{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Must be first!\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    ReduceLROnPlateau,\n",
    "    LambdaLR\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "###################\n",
    "from model import EEGMobileNet\n",
    "from dataset import EEGDatasetV2\n",
    "# from utils import collate_fn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "###################\n",
    "\n",
    "# Set seeds and deterministic flags\n",
    "random.seed(69)\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "torch.cuda.manual_seed(69)\n",
    "torch.use_deterministic_algorithms(True)  # Enable full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5_504_008, 69)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>event_id</th><th>orig_marker</th><th>time</th><th>Fp1</th><th>Fpz</th><th>Fp2</th><th>F7</th><th>F3</th><th>Fz</th><th>F4</th><th>F8</th><th>FC5</th><th>FC1</th><th>FC2</th><th>FC6</th><th>M1</th><th>T7</th><th>C3</th><th>Cz</th><th>C4</th><th>T8</th><th>M2</th><th>CP5</th><th>CP1</th><th>CP2</th><th>CP6</th><th>P7</th><th>P3</th><th>Pz</th><th>P4</th><th>P8</th><th>POz</th><th>O1</th><th>O2</th><th>AF7</th><th>AF3</th><th>AF4</th><th>AF8</th><th>F5</th><th>F1</th><th>F2</th><th>F6</th><th>FC3</th><th>FCz</th><th>FC4</th><th>C5</th><th>C1</th><th>C2</th><th>C6</th><th>CP3</th><th>CP4</th><th>P5</th><th>P1</th><th>P2</th><th>P6</th><th>PO5</th><th>PO3</th><th>PO4</th><th>PO6</th><th>FT7</th><th>FT8</th><th>TP7</th><th>TP8</th><th>PO7</th><th>PO8</th><th>Oz</th><th>prev_prev_marker</th><th>prev_marker</th><th>marker</th></tr><tr><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;Stimulus/P&quot;</td><td>22.746</td><td>-21.377546</td><td>-3.329028</td><td>-18.758145</td><td>-30.73564</td><td>-27.979262</td><td>-17.733182</td><td>-11.122367</td><td>10.858938</td><td>-44.451512</td><td>-12.26531</td><td>-11.228322</td><td>-7.163317</td><td>-14.05838</td><td>-30.227744</td><td>-31.09242</td><td>-12.310457</td><td>-37.415239</td><td>-10.066313</td><td>-17.291664</td><td>-34.362408</td><td>11.172778</td><td>-5.593829</td><td>-11.168018</td><td>-35.016279</td><td>-24.367157</td><td>-11.756309</td><td>-25.158083</td><td>-11.400707</td><td>-9.222274</td><td>-26.857691</td><td>-28.989126</td><td>-35.296483</td><td>-18.676274</td><td>-2.265123</td><td>-0.681522</td><td>-27.036101</td><td>-17.27791</td><td>-14.018948</td><td>-0.860448</td><td>-24.590269</td><td>-11.165179</td><td>-15.876778</td><td>-15.611566</td><td>-15.470771</td><td>-11.342499</td><td>-0.354879</td><td>-47.082836</td><td>-25.75458</td><td>-23.214993</td><td>-28.41397</td><td>-32.145426</td><td>-23.09293</td><td>-18.515905</td><td>-18.41682</td><td>-2.948578</td><td>-29.370747</td><td>-31.412779</td><td>-7.822252</td><td>-27.387539</td><td>-27.833376</td><td>-17.620415</td><td>-29.850262</td><td>-16.782366</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Right&quot;</td></tr><tr><td>0</td><td>&quot;Stimulus/P&quot;</td><td>22.748</td><td>-21.219501</td><td>-3.171698</td><td>-18.695978</td><td>-30.899023</td><td>-27.964396</td><td>-17.633559</td><td>-10.771049</td><td>11.624404</td><td>-44.61444</td><td>-11.903594</td><td>-10.694397</td><td>-7.173872</td><td>-14.512791</td><td>-29.422429</td><td>-30.804771</td><td>-11.544276</td><td>-37.174302</td><td>-5.694034</td><td>-15.207482</td><td>-34.277941</td><td>11.258942</td><td>-5.45682</td><td>-11.079793</td><td>-34.895782</td><td>-24.831925</td><td>-11.852139</td><td>-25.596388</td><td>-11.766606</td><td>-9.404878</td><td>-27.45209</td><td>-29.890226</td><td>-35.150051</td><td>-18.198552</td><td>-1.781131</td><td>-0.387058</td><td>-26.465131</td><td>-16.855895</td><td>-13.527142</td><td>0.034495</td><td>-24.553398</td><td>-10.965987</td><td>-15.584374</td><td>-15.866586</td><td>-15.515992</td><td>-11.014299</td><td>-0.915622</td><td>-47.12713</td><td>-25.906854</td><td>-23.593264</td><td>-28.479127</td><td>-32.260117</td><td>-23.671744</td><td>-18.869104</td><td>-18.846811</td><td>-3.254924</td><td>-30.022285</td><td>-31.631908</td><td>-6.706748</td><td>-27.717578</td><td>-26.271575</td><td>-17.999255</td><td>-30.66878</td><td>-17.174672</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Right&quot;</td></tr><tr><td>0</td><td>&quot;Stimulus/P&quot;</td><td>22.75</td><td>-21.107591</td><td>-3.092899</td><td>-18.653458</td><td>-31.489265</td><td>-28.012768</td><td>-17.474946</td><td>-10.519029</td><td>12.088246</td><td>-45.094286</td><td>-11.5613</td><td>-10.089097</td><td>-7.148177</td><td>-15.480021</td><td>-28.509242</td><td>-30.69717</td><td>-10.76844</td><td>-36.881722</td><td>-3.919959</td><td>-13.700795</td><td>-34.221406</td><td>11.324101</td><td>-5.275087</td><td>-10.958402</td><td>-34.506983</td><td>-25.011003</td><td>-11.901826</td><td>-25.887634</td><td>-12.305291</td><td>-9.472896</td><td>-27.557485</td><td>-30.611738</td><td>-35.342925</td><td>-17.875566</td><td>-1.327837</td><td>-0.237936</td><td>-25.884175</td><td>-16.47395</td><td>-13.142645</td><td>0.856802</td><td>-24.602636</td><td>-10.661366</td><td>-15.28256</td><td>-16.268992</td><td>-15.581594</td><td>-10.649388</td><td>-1.149936</td><td>-47.226449</td><td>-26.028439</td><td>-23.705772</td><td>-28.537429</td><td>-32.317398</td><td>-24.173332</td><td>-18.842379</td><td>-18.952802</td><td>-3.564849</td><td>-30.51049</td><td>-32.262253</td><td>-5.861874</td><td>-28.14821</td><td>-25.338115</td><td>-17.990954</td><td>-31.322179</td><td>-16.965819</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Right&quot;</td></tr><tr><td>0</td><td>&quot;Stimulus/P&quot;</td><td>22.752</td><td>-21.006886</td><td>-3.056991</td><td>-18.582953</td><td>-32.411302</td><td>-28.069638</td><td>-17.238215</td><td>-10.384327</td><td>12.253836</td><td>-45.787117</td><td>-11.235732</td><td>-9.436472</td><td>-7.044266</td><td>-16.833204</td><td>-27.524872</td><td>-30.745046</td><td>-10.0373</td><td>-36.523804</td><td>-4.812991</td><td>-12.846942</td><td>-34.155775</td><td>11.375401</td><td>-5.041548</td><td>-10.786247</td><td>-33.837596</td><td>-24.853686</td><td>-11.903567</td><td>-25.986433</td><td>-12.937813</td><td>-9.399739</td><td>-27.148928</td><td>-31.042835</td><td>-35.812823</td><td>-17.689045</td><td>-0.922058</td><td>-0.185608</td><td>-25.297602</td><td>-16.130204</td><td>-12.878529</td><td>1.541432</td><td>-24.679923</td><td>-10.259005</td><td>-14.956661</td><td>-16.743237</td><td>-15.629367</td><td>-10.255516</td><td>-0.988882</td><td>-47.336807</td><td>-26.087693</td><td>-23.51264</td><td>-28.561456</td><td>-32.291279</td><td>-24.516449</td><td>-18.415956</td><td>-18.701083</td><td>-3.820157</td><td>-30.758124</td><td>-33.167084</td><td>-5.325221</td><td>-28.585937</td><td>-25.039198</td><td>-17.584963</td><td>-31.720538</td><td>-16.191491</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Right&quot;</td></tr><tr><td>0</td><td>&quot;Stimulus/P&quot;</td><td>22.754</td><td>-20.872785</td><td>-3.017698</td><td>-18.431995</td><td>-33.530736</td><td>-28.07893</td><td>-16.911503</td><td>-10.372313</td><td>12.147042</td><td>-46.564886</td><td>-10.917663</td><td>-8.764207</td><td>-6.83163</td><td>-18.402727</td><td>-26.528758</td><td>-30.907434</td><td>-9.397617</td><td>-36.09857</td><td>-8.137851</td><td>-12.662949</td><td>-34.050964</td><td>11.419024</td><td>-4.761436</td><td>-10.570737</td><td>-32.913805</td><td>-24.350841</td><td>-11.86542</td><td>-25.886998</td><td>-13.604752</td><td>-9.183589</td><td>-26.25909</td><td>-31.129443</td><td>-36.458857</td><td>-17.601949</td><td>-0.578673</td><td>-0.170892</td><td>-24.714531</td><td>-15.811797</td><td>-12.733076</td><td>2.042612</td><td>-24.727222</td><td>-9.773674</td><td>-14.59811</td><td>-17.214512</td><td>-15.624975</td><td>-9.844416</td><td>-0.423997</td><td>-47.41706</td><td>-26.072529</td><td>-23.013341</td><td>-28.529877</td><td>-32.175476</td><td>-24.660389</td><td>-17.617972</td><td>-18.101536</td><td>-3.988149</td><td>-30.737496</td><td>-34.17095</td><td>-5.110807</td><td>-28.945567</td><td>-25.33534</td><td>-16.816198</td><td>-31.824498</td><td>-14.951163</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Right&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>2751</td><td>&quot;Stimulus/A&quot;</td><td>956.836</td><td>-18.873559</td><td>-24.227101</td><td>-13.486943</td><td>-0.403397</td><td>-11.98354</td><td>-16.557347</td><td>-17.518873</td><td>-14.536315</td><td>-6.105563</td><td>-10.793705</td><td>-4.853747</td><td>-7.456738</td><td>10.414136</td><td>-2.954412</td><td>-5.026366</td><td>5.687796</td><td>-2.821944</td><td>3.946126</td><td>4.366952</td><td>-0.86041</td><td>-2.708516</td><td>3.370458</td><td>7.267404</td><td>2.82558</td><td>2.815112</td><td>-1.849568</td><td>9.221112</td><td>7.698055</td><td>2.700318</td><td>3.765467</td><td>4.554788</td><td>6.173636</td><td>-7.883982</td><td>-18.15556</td><td>-1.624224</td><td>-10.617139</td><td>-18.317587</td><td>-17.6747</td><td>-16.561863</td><td>-4.705041</td><td>-4.589931</td><td>1.813413</td><td>-4.839258</td><td>-4.689196</td><td>0.565952</td><td>-2.825098</td><td>-4.87889</td><td>4.368522</td><td>-1.258749</td><td>4.727739</td><td>7.158111</td><td>5.224539</td><td>2.009805</td><td>2.215446</td><td>9.938263</td><td>10.332691</td><td>0.287628</td><td>-6.543679</td><td>5.453187</td><td>0.753634</td><td>3.273086</td><td>10.787134</td><td>5.02536</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Left&quot;</td></tr><tr><td>2751</td><td>&quot;Stimulus/A&quot;</td><td>956.838</td><td>-18.704103</td><td>-24.969565</td><td>-14.585048</td><td>-1.047141</td><td>-11.943701</td><td>-16.45773</td><td>-17.959561</td><td>-15.664664</td><td>-7.082881</td><td>-11.007107</td><td>-5.073525</td><td>-8.186207</td><td>8.59455</td><td>-4.468591</td><td>-5.374392</td><td>5.653907</td><td>-2.543513</td><td>2.916711</td><td>1.86508</td><td>-2.226537</td><td>-2.766756</td><td>3.701948</td><td>7.189953</td><td>0.664609</td><td>2.01553</td><td>-1.72148</td><td>9.666301</td><td>7.382395</td><td>2.65323</td><td>2.507406</td><td>4.086716</td><td>5.953678</td><td>-7.897042</td><td>-18.654489</td><td>-2.907517</td><td>-10.716993</td><td>-18.135785</td><td>-18.222283</td><td>-17.620759</td><td>-5.103536</td><td>-4.95171</td><td>1.615306</td><td>-5.864539</td><td>-4.802275</td><td>0.860669</td><td>-3.010969</td><td>-5.317478</td><td>4.972083</td><td>-2.620815</td><td>4.514949</td><td>7.682226</td><td>5.731373</td><td>0.435993</td><td>0.715036</td><td>10.155613</td><td>10.351784</td><td>-0.944356</td><td>-7.749362</td><td>3.527842</td><td>-0.227262</td><td>1.671753</td><td>10.779771</td><td>4.207392</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Left&quot;</td></tr><tr><td>2751</td><td>&quot;Stimulus/A&quot;</td><td>956.84</td><td>-18.061667</td><td>-25.302962</td><td>-15.126122</td><td>-1.543149</td><td>-11.638041</td><td>-16.168372</td><td>-18.234343</td><td>-16.689475</td><td>-7.844465</td><td>-11.080084</td><td>-5.22795</td><td>-8.864504</td><td>6.983161</td><td>-5.717354</td><td>-5.553369</td><td>5.590639</td><td>-2.268625</td><td>1.711394</td><td>-0.604882</td><td>-3.276609</td><td>-2.707251</td><td>3.97878</td><td>6.988798</td><td>-1.132993</td><td>1.500356</td><td>-1.638895</td><td>10.013091</td><td>6.84536</td><td>2.529954</td><td>1.345095</td><td>3.459218</td><td>5.952675</td><td>-7.653053</td><td>-18.907577</td><td>-3.972871</td><td>-10.577918</td><td>-17.735399</td><td>-18.616241</td><td>-18.516636</td><td>-5.395328</td><td>-5.275623</td><td>1.45044</td><td>-6.564501</td><td>-4.839488</td><td>1.135505</td><td>-3.189045</td><td>-5.473588</td><td>5.565337</td><td>-3.532208</td><td>4.463409</td><td>8.272403</td><td>6.121259</td><td>-0.84287</td><td>-0.486312</td><td>10.264764</td><td>10.23355</td><td>-2.014752</td><td>-9.047787</td><td>1.966788</td><td>-1.368454</td><td>0.333598</td><td>10.611117</td><td>3.436481</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Left&quot;</td></tr><tr><td>2751</td><td>&quot;Stimulus/A&quot;</td><td>956.842</td><td>-17.023192</td><td>-25.220666</td><td>-15.079919</td><td>-1.852834</td><td>-11.10314</td><td>-15.743369</td><td>-18.338312</td><td>-17.531294</td><td>-8.309149</td><td>-11.006394</td><td>-5.293303</td><td>-9.428791</td><td>5.715629</td><td>-6.592615</td><td>-5.547356</td><td>5.501853</td><td>-2.008694</td><td>0.434555</td><td>-2.88224</td><td>-3.923841</td><td>-2.530573</td><td>4.190703</td><td>6.70415</td><td>-2.430261</td><td>1.293626</td><td>-1.613443</td><td>10.266805</td><td>6.137341</td><td>2.336787</td><td>0.363123</td><td>2.739203</td><td>6.169374</td><td>-7.181344</td><td>-18.903561</td><td>-4.734289</td><td>-10.219783</td><td>-17.170485</td><td>-18.840451</td><td>-19.18934</td><td>-5.546836</td><td>-5.528552</td><td>1.357458</td><td>-6.879141</td><td>-4.784823</td><td>1.373481</td><td>-3.355288</td><td>-5.336791</td><td>6.114987</td><td>-3.940727</td><td>4.575404</td><td>8.896693</td><td>6.400383</td><td>-1.731706</td><td>-1.306744</td><td>10.309981</td><td>10.048173</td><td>-2.819302</td><td>-10.318089</td><td>0.896298</td><td>-2.548241</td><td>-0.638066</td><td>10.358187</td><td>2.779875</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Left&quot;</td></tr><tr><td>2751</td><td>&quot;Stimulus/A&quot;</td><td>956.844</td><td>-15.701089</td><td>-24.752977</td><td>-14.476695</td><td>-1.950724</td><td>-10.3944</td><td>-15.239857</td><td>-18.279968</td><td>-18.132181</td><td>-8.422661</td><td>-10.790637</td><td>-5.252124</td><td>-9.825349</td><td>4.897406</td><td>-7.017004</td><td>-5.353847</td><td>5.392925</td><td>-1.770672</td><td>-0.797842</td><td>-4.821561</td><td>-4.115736</td><td>-2.2452</td><td>4.333632</td><td>6.381522</td><td>-3.137293</td><td>1.397751</td><td>-1.646783</td><td>10.438867</td><td>5.327027</td><td>2.093779</td><td>-0.366215</td><td>2.004391</td><td>6.583987</td><td>-6.526273</td><td>-18.653626</td><td>-5.137994</td><td>-9.679311</td><td>-16.501842</td><td>-18.890446</td><td>-19.601342</td><td>-5.534951</td><td>-5.680605</td><td>1.371231</td><td>-6.782775</td><td>-4.629448</td><td>1.566671</td><td>-3.503027</td><td>-4.91867</td><td>6.590366</td><td>-3.842274</td><td>4.84218</td><td>9.515511</td><td>6.577467</td><td>-2.173789</td><td>-1.7023</td><td>10.333644</td><td>9.864492</td><td>-3.275397</td><td>-11.438203</td><td>0.399305</td><td>-3.641922</td><td>-1.177381</td><td>10.09657</td><td>2.291098</td><td>&quot;Left&quot;</td><td>&quot;Right&quot;</td><td>&quot;Left&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5_504_008, 69)\n",
       "┌──────────┬────────────┬─────────┬────────────┬───┬────────────┬────────────┬────────────┬────────┐\n",
       "│ event_id ┆ orig_marke ┆ time    ┆ Fp1        ┆ … ┆ Oz         ┆ prev_prev_ ┆ prev_marke ┆ marker │\n",
       "│ ---      ┆ r          ┆ ---     ┆ ---        ┆   ┆ ---        ┆ marker     ┆ r          ┆ ---    │\n",
       "│ i64      ┆ ---        ┆ f64     ┆ f64        ┆   ┆ f64        ┆ ---        ┆ ---        ┆ str    │\n",
       "│          ┆ str        ┆         ┆            ┆   ┆            ┆ str        ┆ str        ┆        │\n",
       "╞══════════╪════════════╪═════════╪════════════╪═══╪════════════╪════════════╪════════════╪════════╡\n",
       "│ 0        ┆ Stimulus/P ┆ 22.746  ┆ -21.377546 ┆ … ┆ -16.782366 ┆ Left       ┆ Right      ┆ Right  │\n",
       "│ 0        ┆ Stimulus/P ┆ 22.748  ┆ -21.219501 ┆ … ┆ -17.174672 ┆ Left       ┆ Right      ┆ Right  │\n",
       "│ 0        ┆ Stimulus/P ┆ 22.75   ┆ -21.107591 ┆ … ┆ -16.965819 ┆ Left       ┆ Right      ┆ Right  │\n",
       "│ 0        ┆ Stimulus/P ┆ 22.752  ┆ -21.006886 ┆ … ┆ -16.191491 ┆ Left       ┆ Right      ┆ Right  │\n",
       "│ 0        ┆ Stimulus/P ┆ 22.754  ┆ -20.872785 ┆ … ┆ -14.951163 ┆ Left       ┆ Right      ┆ Right  │\n",
       "│ …        ┆ …          ┆ …       ┆ …          ┆ … ┆ …          ┆ …          ┆ …          ┆ …      │\n",
       "│ 2751     ┆ Stimulus/A ┆ 956.836 ┆ -18.873559 ┆ … ┆ 5.02536    ┆ Left       ┆ Right      ┆ Left   │\n",
       "│ 2751     ┆ Stimulus/A ┆ 956.838 ┆ -18.704103 ┆ … ┆ 4.207392   ┆ Left       ┆ Right      ┆ Left   │\n",
       "│ 2751     ┆ Stimulus/A ┆ 956.84  ┆ -18.061667 ┆ … ┆ 3.436481   ┆ Left       ┆ Right      ┆ Left   │\n",
       "│ 2751     ┆ Stimulus/A ┆ 956.842 ┆ -17.023192 ┆ … ┆ 2.779875   ┆ Left       ┆ Right      ┆ Left   │\n",
       "│ 2751     ┆ Stimulus/A ┆ 956.844 ┆ -15.701089 ┆ … ┆ 2.291098   ┆ Left       ┆ Right      ┆ Left   │\n",
       "└──────────┴────────────┴─────────┴────────────┴───┴────────────┴────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('/home/owner/Documents/DEV/BrainLabyrinth/data/combined_prev_prev_2.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_set, train_loader, val_loader, writer):\n",
    "    # -------------------- MODEL --------------------\n",
    "    model = EEGMobileNet(\n",
    "        in_channels=65,\n",
    "        num_classes=1,\n",
    "        dropout=config['dropout']\n",
    "    ).to(config['device'])\n",
    "        \n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.BatchNorm1d):\n",
    "            assert not layer.track_running_stats, \\\n",
    "                f\"BatchNorm layer {name} should have track_running_stats=False\"\n",
    "    \n",
    "    # Log model architecture and config\n",
    "    writer.add_text(\"Model/Type\", f\"EEGMobileNet with dropout={config['dropout']}\")\n",
    "    writer.add_text(\"Model/Structure\", str(model))\n",
    "    writer.add_text(\"Training Config\", str(config))\n",
    "    \n",
    "    # ------------------ LOSS FUNCTION ------------------\n",
    "    \n",
    "    \n",
    "    class_counts = train_set.class_weights # Fetches {'Left_count': N, 'Right_count': M}\n",
    "\n",
    "    count_L = class_counts.get('Left', 1)  # Default to 1 to prevent division by zero errors later\n",
    "    count_R = class_counts.get('Right', 1)  # Default to 1\n",
    "\n",
    "    # Calculate the pos_weight value = count_negative / count_positive\n",
    "    # Add a check for count_R being zero\n",
    "    if count_R > 0:\n",
    "        pos_weight_value = count_L / count_R\n",
    "    else:\n",
    "        pos_weight_value = 1.0 # Assign a default weight if the positive class has zero samples\n",
    "        print(f\"Warning: Positive class (Right/1) has count {count_R}. Setting pos_weight to 1.0.\")\n",
    "\n",
    "    print(f\"Class counts: Left={count_L}, Right={count_R}\")\n",
    "    print(f\"Calculated pos_weight for BCEWithLogitsLoss: {pos_weight_value:.4f}\")\n",
    "    \n",
    "    pos_weight = torch.tensor([pos_weight_value]).to(config['device'])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight=pos_weight)\n",
    "    \n",
    "    # ------------------- OPTIMIZER ---------------------\n",
    "    lr = config.get('lr', 1e-3)\n",
    "    weight_decay = config.get('weight_decay', 1e-2)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # ------------------- SCHEDULER ---------------------\n",
    "    scheduler_config = config.get('scheduler', {})\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=scheduler_config.get('mode', 'min'),\n",
    "        factor=scheduler_config.get('factor', 0.1),\n",
    "        patience=scheduler_config.get('patience', 10),\n",
    "        threshold=scheduler_config.get('threshold', 0.0001),\n",
    "        cooldown=scheduler_config.get('cooldown', 0),\n",
    "        min_lr=scheduler_config.get('min_lr', 0),\n",
    "    )\n",
    "    \n",
    "    # ------------------- WARMUP SCHEDULER ---------------\n",
    "    warmup_epochs = config.get('warmup_epochs', 0)\n",
    "    if warmup_epochs > 0:\n",
    "        warmup_scheduler = LambdaLR(\n",
    "            optimizer,\n",
    "            lambda epoch: min(1.0, (epoch + 1) / warmup_epochs)\n",
    "        )\n",
    "    else:\n",
    "        warmup_scheduler = None\n",
    "    \n",
    "    # -------------------- TRAINING LOOP --------------------\n",
    "    best_metric = -float('inf')\n",
    "    \n",
    "    for epoch in tqdm(range(config['epochs']), desc=\"Training\"):\n",
    "        # ---------- TRAIN ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for labels, features, _ in train_loader:\n",
    "            features = features.to(config['device']).float()\n",
    "            labels = labels.to(config['device']).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (if specified)\n",
    "            if config.get('grad_clip') is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # ---------- VALIDATION ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for labels, features, _ in val_loader:\n",
    "                features = features.to(config['device']).float()\n",
    "                labels = labels.to(config['device']).float()\n",
    "                \n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        predictions = (np.array(all_preds) > 0.5).astype(int)\n",
    "        \n",
    "        # ---------- METRICS ----------\n",
    "        accuracy = accuracy_score(all_labels, predictions)\n",
    "        precision = precision_score(all_labels, predictions)\n",
    "        recall = recall_score(all_labels, predictions)\n",
    "        f1 = f1_score(all_labels, predictions)\n",
    "        \n",
    "        # ---------- SCHEDULER UPDATE ----------\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if warmup_scheduler is not None and epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "        \n",
    "        # ---------- LOGGING ----------\n",
    "        writer.add_scalar('LR', current_lr, epoch)\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        writer.add_scalar('F1', f1, epoch)\n",
    "        \n",
    "        # You can also combine them in a single dictionary\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "        writer.add_scalars('Metrics', metrics, epoch)\n",
    "        \n",
    "        # ---------- SAVE BEST MODEL ----------\n",
    "        if accuracy > best_metric:\n",
    "            best_metric = accuracy\n",
    "            torch.save(model.state_dict(), f\"{config['log_dir']}/best_model.pth\")\n",
    "    \n",
    "    writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 7.874218712024844e-05,\n",
       " 'weight_decay': 6.044655803896766e-06,\n",
       " 'dropout': 0.4991027500704538,\n",
       " 'factor': 0.127815027666582,\n",
       " 'patience': 18,\n",
       " 'cooldown': 12}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('baseline_CNN_V2.pkl', 'rb') as f:\n",
    "    config_study = pickle.load(f)\n",
    "    \n",
    "required_keys = ['lr', 'weight_decay', 'dropout', 'factor', 'patience', 'cooldown']\n",
    "assert all(k in config_study for k in required_keys), \\\n",
    "    f\"Missing Optuna parameters: {set(required_keys) - set(config_study.keys())}\"\n",
    "    \n",
    "config_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': '/home/owner/Documents/DEV/BrainLabyrinth/data/combined_prev_prev_2.parquet',\n",
    "    'split_ratios': (0.7, 0.15, 0.15),\n",
    "    'batch_size': 32,\n",
    "    'dropout': config_study['dropout'],\n",
    "    'epochs': 300,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_dir': './runs/CNN',\n",
    "\n",
    "    # <<< Global LR and Weight Decay here >>>\n",
    "    'lr': config_study['lr'],\n",
    "    'weight_decay': config_study['weight_decay'],\n",
    "    'factor': config_study['factor'],\n",
    "    'patience': config_study['patience'],\n",
    "    'cooldown': config_study['cooldown'],\n",
    "    \n",
    "    # Optimizer config (without lr/weight_decay)\n",
    "    'optimizer': {\n",
    "        'mode': 'min',\n",
    "        'factor': config_study['factor'],      # From Optuna\n",
    "        'patience': config_study['patience'],  # From Optuna\n",
    "        'cooldown': config_study['cooldown'],  # From Optuna\n",
    "        'min_lr': 1e-8,\n",
    "        'threshold': 0.0001,\n",
    "    },\n",
    "\n",
    "    # Scheduler config\n",
    "    'scheduler': {\n",
    "        'mode': 'min',\n",
    "        'factor': config_study['factor'],\n",
    "        'patience': config_study['patience'],\n",
    "        'threshold': 0.0001,\n",
    "        'cooldown': config_study['cooldown'],\n",
    "        'min_lr': 1e-8\n",
    "    },\n",
    "\n",
    "    'warmup_epochs': 0,\n",
    "    'grad_clip': None\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating full dataset...\n",
      "['event_id', 'orig_marker', 'time', 'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz', 'prev_prev_marker', 'prev_marker', 'marker']\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b9e91b38ab4c93be05e1d7dc6ef516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "precomputing_samples:   0%|          | 0/2752 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "{'Left': 0.0007331378299120235, 'Right': 0.0007204610951008645}\n",
      "Splitting the dataset...\n",
      "['event_id', 'orig_marker', 'time', 'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz', 'prev_prev_marker', 'prev_marker', 'marker']\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8124584493409fa6b0c5ff877c3f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "precomputing_samples:   0%|          | 0/1926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "['event_id', 'orig_marker', 'time', 'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz', 'prev_prev_marker', 'prev_marker', 'marker']\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab56c704b28481486e071143598b54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "precomputing_samples:   0%|          | 0/412 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "['event_id', 'orig_marker', 'time', 'Fp1', 'Fpz', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC5', 'FC1', 'FC2', 'FC6', 'M1', 'T7', 'C3', 'Cz', 'C4', 'T8', 'M2', 'CP5', 'CP1', 'CP2', 'CP6', 'P7', 'P3', 'Pz', 'P4', 'P8', 'POz', 'O1', 'O2', 'AF7', 'AF3', 'AF4', 'AF8', 'F5', 'F1', 'F2', 'F6', 'FC3', 'FCz', 'FC4', 'C5', 'C1', 'C2', 'C6', 'CP3', 'CP4', 'P5', 'P1', 'P2', 'P6', 'PO5', 'PO3', 'PO4', 'PO6', 'FT7', 'FT8', 'TP7', 'TP8', 'PO7', 'PO8', 'Oz', 'prev_prev_marker', 'prev_marker', 'marker']\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7927c5d37a40d9bd2e3dbcf8bd3a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "precomputing_samples:   0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "unbalanced train dataset shape: (1926, [labels: torch.Size([]), features: [2000, 65]])\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Training Pipeline\n",
    "#============================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialize dataset\n",
    "print(\"Creating full dataset...\")\n",
    "full_dataset = EEGDatasetV2(config['data_path'])\n",
    "\n",
    "print(full_dataset.class_weights)\n",
    "\n",
    "print(\"Splitting the dataset...\")\n",
    "# Split dataset\n",
    "train_set, val_set, test_set = full_dataset.split_dataset(\n",
    "    ratios=config['split_ratios']\n",
    ")\n",
    "\n",
    "del full_dataset\n",
    "\n",
    "len_dataset = len(train_set)\n",
    "sample = train_set[0]\n",
    "label_shape = sample[0].shape\n",
    "feature_shape = sample[1].shape\n",
    "\n",
    "print(f\"unbalanced train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "torch.save(train_set, 'train_set.pt')\n",
    "torch.save(val_set, 'val_set.pt')\n",
    "torch.save(test_set, 'test_set.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (1926, [labels: torch.Size([]), features: [2000, 65]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = torch.load('train_set.pt', weights_only=False)\n",
    "val_set = torch.load('val_set.pt', weights_only=False)\n",
    "test_set = torch.load('test_set.pt', weights_only=False)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Collate function for variable-length EEG feature sequences.\n",
    "\n",
    "    Each sample is expected to be a tuple (label, feature), where:\n",
    "    - label is a scalar tensor (or 1D tensor) representing the class/target.\n",
    "    - feature is a tensor of shape (seq_len, num_channels), where seq_len may vary.\n",
    "\n",
    "    This function stacks labels and pads features along the time dimension so that\n",
    "    all sequences in the batch have the same length.\n",
    "    \"\"\"\n",
    "    # Unzip the batch into labels and features\n",
    "    labels, features, original_labels = zip(*batch)\n",
    "    \n",
    "    labels = torch.stack(labels)\n",
    "    padded_features = pad_sequence(features, batch_first=True)\n",
    "    original_labels = torch.stack(original_labels)\n",
    "\n",
    "    \n",
    "    return labels, padded_features, original_labels\n",
    "\n",
    "\n",
    "generator = torch.Generator().manual_seed(69)  # Set seed\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    generator=generator,  # Add this line\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(val_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "\n",
    "len_dataset = len(train_set)\n",
    "sample = train_set[0]\n",
    "label_shape = sample[0].shape\n",
    "feature_shape = sample[1].shape\n",
    "\n",
    "print(f\"train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "writer = SummaryWriter(log_dir=config['log_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_set.df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying seeds immediately before training...\n",
      "Class counts: Left=0.0010787486515641855, Right=0.001001001001001001\n",
      "Calculated pos_weight for BCEWithLogitsLoss: 1.0777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd14d7858c64457b77d0f1782398234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "print(\"Applying seeds immediately before training...\")\n",
    "random.seed(69)\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "torch.cuda.manual_seed(69)\n",
    "# Ensure deterministic algorithms are still enabled (should be from top)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "trained_model = train_model(config, train_set, train_loader, val_loader, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a9e57d6500848a0b05f2a4b46289fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "best_model = EEGMobileNet(in_channels=65)  # Adjust parameters as needed\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(f\"{config['log_dir']}/best_model.pth\", map_location=config['device'])\n",
    "best_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move model to the correct device\n",
    "best_model = best_model.to(config['device'])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "best_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "all_test_markers = []\n",
    "all_test_predictions = []\n",
    "all_test_original_markers = []\n",
    "with torch.no_grad():\n",
    "    for markers, features, original_markers in tqdm(test_loader):\n",
    "        features = features.to(config['device'])\n",
    "        markers = markers.to(config['device'])\n",
    "\n",
    "        outputs = best_model(features)\n",
    "\n",
    "        # Collect markers and predictions for metrics calculation\n",
    "        all_test_markers.extend(markers.cpu().numpy().flatten())\n",
    "        all_test_predictions.extend(torch.sigmoid(outputs).cpu().numpy().flatten())\n",
    "        all_test_original_markers.extend(original_markers.cpu().numpy().flatten())\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_precision = precision_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_recall = recall_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_f1 = f1_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_roc_auc = roc_auc_score(all_test_markers, all_test_predictions)\n",
    "\n",
    "# Log test metrics to TensorBoard\n",
    "writer.add_scalar('Metrics/test_accuracy', test_accuracy, 1)\n",
    "writer.add_scalar('Metrics/test_precision', test_precision, 1)\n",
    "writer.add_scalar('Metrics/test_recall', test_recall, 1)\n",
    "writer.add_scalar('Metrics/test_f1', test_f1, 1)\n",
    "writer.add_scalar('Metrics/test_roc_auc', test_roc_auc, 1)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_accuracy=0.642512077294686\n",
      "test_precision=0.5958549222797928\n",
      "test_recall=0.6216216216216216\n",
      "test_f1=0.6084656084656085\n",
      "test_roc_auc=np.float64(0.6943231441048034)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{test_accuracy=}\n",
    "{test_precision=}\n",
    "{test_recall=}\n",
    "{test_f1=}\n",
    "{test_roc_auc=}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d119a9036d2040a3b2a0baffa9bf21cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.3699999999999999)\n",
      "best_f1=0.6823529411764706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_recall = f1_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_recall > best_f1:\n",
    "        best_f1 = current_recall\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"{best_f1=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cadd5873ed2546779e96273cbf11b33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.4)\n",
      "\n",
      "best_accuracy=0.678743961352657\n",
      "precision=0.6130434782608696\n",
      "recall=0.7621621621621621\n",
      "f1=0.6795180722891566\n",
      "roc_auc=np.float64(0.6943231441048034)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "best_threshold = 0.1\n",
    "best_accuracy = 0.0\n",
    "thresholds = np.arange(0.005, 1.0, 0.005)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int) \n",
    "    current_recall = accuracy_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_recall > best_accuracy:\n",
    "        best_accuracy = current_recall\n",
    "        best_threshold = threshold\n",
    "        precision = precision_score(all_test_markers, [1 if p > threshold else 0 for p in all_test_predictions])\n",
    "        recall = recall_score(all_test_markers, [1 if p > threshold else 0 for p in all_test_predictions])\n",
    "        f1 = f1_score(all_test_markers, [1 if p > threshold else 0 for p in all_test_predictions])\n",
    "        roc_auc = roc_auc_score(all_test_markers, all_test_predictions)\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"\"\"\n",
    "{best_accuracy=}\n",
    "{precision=}\n",
    "{recall=}\n",
    "{f1=}\n",
    "{roc_auc=}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Metrics Based on Rule Application Success ---\n",
      "Total Events Analyzed (A + P): 414\n",
      "--------------------\n",
      "Stimulus/A Events: 268\n",
      "  - Rule 'Flip' Correct: 219\n",
      "  - Rule 'Flip' Incorrect: 49\n",
      "  - Accuracy of 'Flip' Rule: 0.8172\n",
      "--------------------\n",
      "Stimulus/P Events: 146\n",
      "  - Rule 'Persist' Correct: 62\n",
      "  - Rule 'Persist' Incorrect: 84\n",
      "  - Accuracy of 'Persist' Rule: 0.4247\n",
      "--------------------\n",
      "Overall Accuracy (Rule matched outcome): 0.6787\n",
      "--------------------\n",
      "\n",
      "Note:\n",
      "These metrics evaluate the success rate of the simple 'Flip'/'Persist' heuristics.\n",
      "They are NOT standard classification metrics like Precision, Recall, or F1-Score \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "statuses = []\n",
    "test_rightness =  all_test_markers == np.array([1 if p > best_threshold else 0 for p in all_test_predictions])\n",
    "for original_marker, positive_verdict in zip(all_test_original_markers, test_rightness):\n",
    "    if original_marker == 1:\n",
    "        if positive_verdict:\n",
    "            statuses.append('Stimulus/P right')\n",
    "        else:\n",
    "            statuses.append('Stimulus/P wrong')\n",
    "    else:\n",
    "        if positive_verdict:\n",
    "            statuses.append('Stimulus/A right')\n",
    "        else:\n",
    "            statuses.append('Stimulus/A wrong')\n",
    "\n",
    "\n",
    "results_counter = Counter(statuses)\n",
    "\n",
    "\n",
    "\n",
    "# --- Extract counts ---\n",
    "# Use .get() for safety in case a key is missing (though not in this example)\n",
    "stim_A_right = results_counter.get('Stimulus/A right', 0)\n",
    "stim_A_wrong = results_counter.get('Stimulus/A wrong', 0)\n",
    "stim_P_right = results_counter.get('Stimulus/P right', 0)\n",
    "stim_P_wrong = results_counter.get('Stimulus/P wrong', 0)\n",
    "\n",
    "# --- Calculate totals ---\n",
    "total_A_events = stim_A_right + stim_A_wrong\n",
    "total_P_events = stim_P_right + stim_P_wrong\n",
    "\n",
    "total_right_predictions = stim_A_right + stim_P_right\n",
    "total_wrong_predictions = stim_A_wrong + stim_P_wrong\n",
    "total_events = total_right_predictions + total_wrong_predictions\n",
    "\n",
    "# --- Calculate Metrics ---\n",
    "\n",
    "# 1. Overall Accuracy of the Rules\n",
    "# (How often did the rule correctly predict the outcome?)\n",
    "overall_accuracy = total_right_predictions / total_events if total_events > 0 else 0.0\n",
    "\n",
    "# 2. Accuracy of Rule A (Flip)\n",
    "# (When Stimulus/A was shown, how often was flipping the correct strategy?)\n",
    "accuracy_A = stim_A_right / total_A_events if total_A_events > 0 else 0.0\n",
    "\n",
    "# 3. Accuracy of Rule P (Persist)\n",
    "# (When Stimulus/P was shown, how often was persisting the correct strategy?)\n",
    "accuracy_P = stim_P_right / total_P_events if total_P_events > 0 else 0.0\n",
    "\n",
    "# --- Print Results ---\n",
    "print(\"--- Metrics Based on Rule Application Success ---\")\n",
    "print(f\"Total Events Analyzed (A + P): {total_events}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Stimulus/A Events: {total_A_events}\")\n",
    "print(f\"  - Rule 'Flip' Correct: {stim_A_right}\")\n",
    "print(f\"  - Rule 'Flip' Incorrect: {stim_A_wrong}\")\n",
    "print(f\"  - Accuracy of 'Flip' Rule: {accuracy_A:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Stimulus/P Events: {total_P_events}\")\n",
    "print(f\"  - Rule 'Persist' Correct: {stim_P_right}\")\n",
    "print(f\"  - Rule 'Persist' Incorrect: {stim_P_wrong}\")\n",
    "print(f\"  - Accuracy of 'Persist' Rule: {accuracy_P:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Overall Accuracy (Rule matched outcome): {overall_accuracy:.4f}\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "print(\"\\nNote:\")\n",
    "print(\"These metrics evaluate the success rate of the simple 'Flip'/'Persist' heuristics.\")\n",
    "print(\"They are NOT standard classification metrics like Precision, Recall, or F1-Score \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
