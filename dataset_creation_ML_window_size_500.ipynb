{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from numpy.lib.stride_tricks import sliding_window_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching unique event IDs...\n",
      "Found 2772 unique events.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing events (large windows):  20%|█▉        | 550/2772 [03:03<12:25,  2.98it/s]"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.signal import welch\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "import math\n",
    "import gc\n",
    "import joblib\n",
    "# ... other imports ...\n",
    "\n",
    "# --- Feature Extraction with Larger Overlapping Windows ---\n",
    "def extract_features_large_windows(group: pl.DataFrame) -> pl.DataFrame:\n",
    "    # Get constant features\n",
    "    event_id = group['event_id'][0]\n",
    "    prev_marker = group['prev_marker'][0]\n",
    "    marker = group['marker'][0] # Target\n",
    "\n",
    "    eeg_cols = [col for col in group.columns if col not in\n",
    "                ['event_id', 'time', 'marker', 'prev_marker', 'orig_marker']]\n",
    "\n",
    "    # --- Configuration for Large Windows ---\n",
    "    fs = 500 # Sampling Frequency\n",
    "    target_len = 2000 # Samples per epoch (4 seconds)\n",
    "    window_size = 500 # Samples (2 seconds) <-- ADJUSTABLE\n",
    "    step_size = 250    # Samples (0.5 seconds for 75% overlap) <-- ADJUSTABLE\n",
    "    # Calculate expected number of windows\n",
    "    num_windows = math.floor((target_len - window_size) / step_size) + 1 if target_len >= window_size else 0\n",
    "    # --- End Configuration ---\n",
    "\n",
    "    features_dict = {\n",
    "        'event_id': event_id,\n",
    "        'prev_marker': prev_marker,\n",
    "        'marker': marker\n",
    "    }\n",
    "\n",
    "    bands = { 'delta': (1, 4), 'theta': (4, 8), 'alpha': (8, 13), 'beta': (13, 30) }\n",
    "    nperseg_welch = min(500, window_size) # Welch window, e.g., 1 sec or window_size if smaller\n",
    "    noverlap_welch = nperseg_welch // 2\n",
    "\n",
    "    # Process each EEG channel\n",
    "    for col in eeg_cols:\n",
    "        signal = group[col].cast(pl.Float64).to_numpy()\n",
    "        signal = np.nan_to_num(signal, nan=0.0)\n",
    "        if len(signal) < target_len:\n",
    "            signal = np.pad(signal, (0, target_len - len(signal)), constant_values=0.0)\n",
    "        elif len(signal) > target_len:\n",
    "            signal = signal[:target_len]\n",
    "\n",
    "        if len(signal) < window_size: # If epoch too short even for one window\n",
    "             for window_idx in range(num_windows): # Add NaNs for all expected features/windows\n",
    "                 # Time domain NaNs\n",
    "                 features_dict[f\"{col}_mean_w{window_idx}\"] = np.nan\n",
    "                 features_dict[f\"{col}_std_w{window_idx}\"] = np.nan\n",
    "                 # ... add NaNs for min, max, skew, kurtosis, mobility, complexity ...\n",
    "                 # Freq domain NaNs\n",
    "                 for band in bands: features_dict[f\"{col}_{band}_power_w{window_idx}\"] = np.nan\n",
    "             continue\n",
    "\n",
    "        # Create sliding windows view\n",
    "        windows = sliding_window_view(signal, window_shape=window_size)[::step_size]\n",
    "\n",
    "        # Calculate features for each window\n",
    "        for window_idx, window_signal in enumerate(windows):\n",
    "            # Ensure we don't process more windows than expected (safety)\n",
    "            if window_idx >= num_windows: break\n",
    "\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                # Basic Stats\n",
    "                features_dict[f\"{col}_mean_w{window_idx}\"] = np.mean(window_signal)\n",
    "                features_dict[f\"{col}_std_w{window_idx}\"] = np.std(window_signal, ddof=1)\n",
    "                features_dict[f\"{col}_min_w{window_idx}\"] = np.min(window_signal)\n",
    "                features_dict[f\"{col}_max_w{window_idx}\"] = np.max(window_signal)\n",
    "                features_dict[f\"{col}_skew_w{window_idx}\"] = stats.skew(window_signal, bias=False)\n",
    "                features_dict[f\"{col}_kurtosis_w{window_idx}\"] = stats.kurtosis(window_signal, bias=False)\n",
    "\n",
    "                # Hjorth Parameters\n",
    "                diff1 = np.diff(window_signal)\n",
    "                diff2 = np.diff(diff1)\n",
    "                var_signal = np.var(window_signal, ddof=1)\n",
    "                var_diff1 = np.var(diff1, ddof=1)\n",
    "                var_diff2 = np.var(diff2, ddof=1)\n",
    "                mobility = np.sqrt(var_diff1 / var_signal) if var_signal > 1e-9 else 0.0\n",
    "                complexity = np.sqrt(var_diff2 / var_diff1) / mobility if mobility > 1e-9 and var_diff1 > 1e-9 else 0.0\n",
    "                features_dict[f\"{col}_mobility_w{window_idx}\"] = mobility\n",
    "                features_dict[f\"{col}_complexity_w{window_idx}\"] = complexity\n",
    "\n",
    "                # Band Power\n",
    "                try:\n",
    "                    freqs, psd = welch(window_signal, fs=fs, nperseg=nperseg_welch, noverlap=noverlap_welch, scaling='density', average='mean')\n",
    "                    for band, (low_hz, high_hz) in bands.items():\n",
    "                        idx_band = np.logical_and(freqs >= low_hz, freqs < high_hz)\n",
    "                        band_power = np.mean(psd[idx_band]) if np.any(idx_band) else 0.0\n",
    "                        features_dict[f\"{col}_{band}_power_w{window_idx}\"] = band_power\n",
    "                except ValueError as e:\n",
    "                    print(f\"Warning: Welch failed for {col} w{window_idx}, event {event_id}: {e}\")\n",
    "                    for band in bands: features_dict[f\"{col}_{band}_power_w{window_idx}\"] = np.nan\n",
    "\n",
    "    return pl.DataFrame([features_dict])\n",
    "\n",
    "\n",
    "# --- Function to Create Dataset (calls extract_features_1000s) ---\n",
    "def create_ml_dataset_large_windows(df_path: str, output_path: str = \"ML_dataset_large_window_features.parquet\", batch_size: int = 100):\n",
    "    # This function remains structurally the same as create_ml_dataset_epoch_features,\n",
    "    # just make sure it calls extract_features_large_windows instead.\n",
    "    # Remember to use a different temp directory name like 'temp_large_window_files'\n",
    "\n",
    "    # Initialize\n",
    "    temp_counter = 0\n",
    "    temp_files = []\n",
    "    processed_batch = []\n",
    "    temp_dir = \"temp_large_window_files\" # Different temp dir\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    lf = pl.scan_parquet(df_path).with_columns(\n",
    "        pl.col(['prev_marker', 'marker']).cast(pl.Utf8),\n",
    "        pl.all().exclude(['event_id', 'time', 'marker', 'prev_marker', 'orig_marker']).cast(pl.Float64)\n",
    "    )\n",
    "\n",
    "    print(\"Fetching unique event IDs...\")\n",
    "    event_ids = lf.select('event_id').unique(maintain_order=True).collect()['event_id'].to_list()\n",
    "    total_events = len(event_ids)\n",
    "    print(f\"Found {total_events} unique events.\")\n",
    "\n",
    "    with tqdm(total=total_events, desc=\"Processing events (large windows)\") as pbar:\n",
    "        for event_id in event_ids:\n",
    "            try:\n",
    "                event_group_lf = lf.filter(pl.col('event_id') == event_id)\n",
    "                event_group_df = event_group_lf.sort('time').collect()\n",
    "\n",
    "                if event_group_df.is_empty():\n",
    "                     pbar.update(1); continue\n",
    "                # Check length, although padding/truncation is handled inside\n",
    "                # if event_group_df.height != 2000:\n",
    "                #      print(f\"Warning: Event {event_id} has {event_group_df.height} samples\")\n",
    "\n",
    "                # *** Call the large window feature extractor ***\n",
    "                processed_df = extract_features_large_windows(event_group_df)\n",
    "                processed_batch.append(processed_df)\n",
    "\n",
    "                if len(processed_batch) >= batch_size:\n",
    "                    temp_file = os.path.join(temp_dir, f\"temp_{temp_counter}.parquet\")\n",
    "                    pl.concat(processed_batch).write_parquet(temp_file, compression=\"zstd\")\n",
    "                    temp_files.append(temp_file)\n",
    "                    processed_batch = []\n",
    "                    temp_counter += 1\n",
    "                    gc.collect()\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing event_id {event_id}: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "    # Write remaining batch\n",
    "    if processed_batch:\n",
    "        temp_file = os.path.join(temp_dir, f\"temp_{temp_counter}.parquet\")\n",
    "        pl.concat(processed_batch).write_parquet(temp_file, compression=\"zstd\")\n",
    "        temp_files.append(temp_file)\n",
    "        print(f\"Wrote final batch of {len(processed_batch)} events.\")\n",
    "\n",
    "    # Combine temporary files\n",
    "    print(f\"Combining {len(temp_files)} temporary batch files...\")\n",
    "    if temp_files:\n",
    "        # ... (Combination and cleanup logic is identical to previous function) ...\n",
    "        try:\n",
    "            lazy_frames = [pl.scan_parquet(f) for f in temp_files]\n",
    "            pl.concat(lazy_frames, rechunk=False).sink_parquet(\n",
    "                output_path, compression=\"zstd\", statistics=True\n",
    "            )\n",
    "            print(f\"Successfully created final dataset: {output_path}\")\n",
    "        except Exception as e:\n",
    "             print(f\"ERROR: Failed during final concatenation/writing: {e}\")\n",
    "             print(f\"Temporary files are kept for inspection in '{temp_dir}'.\")\n",
    "             return None\n",
    "        finally:\n",
    "             if os.path.exists(output_path):\n",
    "                 print(\"Cleaning up temporary files...\")\n",
    "                 for f in temp_files:\n",
    "                     try: os.remove(f)\n",
    "                     except OSError as e: print(f\"Warning: Could not remove temp file {f}: {e}\")\n",
    "                 try: os.rmdir(temp_dir); print(f\"Removed temporary directory: {temp_dir}\")\n",
    "                 except OSError: print(f\"Temporary directory {temp_dir} not empty, not removed.\")\n",
    "                 print(\"Cleanup complete.\")\n",
    "             else:\n",
    "                 print(f\"Final file not created. Keeping temporary files in '{temp_dir}'.\")\n",
    "        return output_path\n",
    "    else:\n",
    "        print(\"No temporary files were generated. No output created.\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# --- Usage Example ---\n",
    "INPUT_FILE = \"/home/owner/Documents/DEV/BrainLabyrinth/data/combined.parquet\"\n",
    "OUTPUT_FILE_LARGE_WINDOW = \"ML_dataset_500_features.parquet\" # New name\n",
    "BATCH_SIZE = 200\n",
    "\n",
    "final_large_window_file_path = create_ml_dataset_large_windows(INPUT_FILE, OUTPUT_FILE_LARGE_WINDOW, BATCH_SIZE)\n",
    "\n",
    "if final_large_window_file_path:\n",
    "    print(f\"\\nLarge window feature dataset creation complete. Output file: {final_large_window_file_path}\")\n",
    "    # Verify schema or head\n",
    "    print(\"\\nSchema of the large window feature dataset:\")\n",
    "    final_lf = pl.scan_parquet(final_large_window_file_path)\n",
    "    print(final_lf.schema)\n",
    "    # Estimate feature count more accurately now\n",
    "    num_features_estimate = len(final_lf.columns) - 3 # Subtract event_id, marker, prev_marker\n",
    "    print(f\"\\nEstimated number of feature columns: {num_features_estimate}\")\n",
    "\n",
    "else:\n",
    "    print(\"\\nLarge window feature dataset creation failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading schema to identify columns...\n",
      "Found 5376 initial feature columns.\n",
      "Target column: marker\n",
      "\n",
      "--- Step 1: Low Variance Threshold ---\n",
      "Fitting StandardScaler incrementally (batch size: 1000)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting Scaler: 100%|██████████| 3/3 [00:00<00:00, 10.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler fitting complete.\n",
      "Saved fitted scaler to fs_scaler_500.joblib\n",
      "Applied Variance Threshold > 0.01\n",
      "Features remaining after variance check: 4899 (removed 477)\n",
      "\n",
      "--- Step 2: Mutual Information Selection ---\n",
      "Sampling data (20000 rows) for MI calculation...\n",
      "Total rows <= sample size, using all data for MI.\n",
      "Sampled 2772 rows.\n",
      "Encoded target variable. Found classes: ['Left' 'Right']\n",
      "Scaling the sample data (using all original features)...\n",
      "Applying variance threshold filter to scaled sample data...\n",
      "Shape of data for MI: (2772, 4899)\n",
      "Calculating Mutual Information scores and selecting top 500 features...\n",
      "Mutual Information selection complete.\n",
      "Final features selected: 500 (removed 4399 based on MI)\n",
      "\n",
      "--- Feature Selection Summary ---\n",
      "Initial features: 5376\n",
      "After Variance Threshold (> 0.01): 4899\n",
      "After Mutual Information (Top 500): 500\n",
      "\n",
      "Saved the final list of 500 selected features to: final_selected_features_500.joblib\n",
      "\n",
      "Feature selection process finished.\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "import gc\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, mutual_info_classif\n",
    "import traceback # Import traceback for detailed error printing\n",
    "\n",
    "# --- Configuration ---\n",
    "# *** IMPORTANT: Update INPUT_FILE to the correct large window features file ***\n",
    "INPUT_FILE = \"ML_dataset_500_features.parquet\" # Use the file generated by the previous step\n",
    "OUTPUT_SCALER_MODEL = \"fs_scaler_500.joblib\" # Use distinct names\n",
    "OUTPUT_FINAL_FEATURE_LIST = \"final_selected_features_500.joblib\" # Use distinct names\n",
    "\n",
    "# Feature Selection Parameters\n",
    "VARIANCE_THRESHOLD = 0.01\n",
    "MI_SELECT_K = 500\n",
    "MI_SAMPLE_SIZE = 20000 # Keep or adjust based on memory\n",
    "BATCH_SIZE = 1000 # For scaler fitting\n",
    "\n",
    "# --- Identify Feature and Target Columns ---\n",
    "print(\"Reading schema to identify columns...\")\n",
    "try:\n",
    "    # Make sure INPUT_FILE exists\n",
    "    if not os.path.exists(INPUT_FILE):\n",
    "        raise FileNotFoundError(f\"Input file not found: {INPUT_FILE}\")\n",
    "    schema = pl.read_parquet(INPUT_FILE, n_rows=0).schema\n",
    "except Exception as e:\n",
    "    print(f\"Error reading schema from {INPUT_FILE}: {e}\")\n",
    "    print(\"Please ensure the file exists and is a valid Parquet file.\")\n",
    "    exit(1) # Use non-zero exit code for errors\n",
    "\n",
    "IDENTIFIER_COLS = ['event_id', 'prev_marker']\n",
    "TARGET_COLUMN = 'marker'\n",
    "# Calculate initial feature columns\n",
    "FEATURE_COLUMNS = [col for col in schema if col not in IDENTIFIER_COLS + [TARGET_COLUMN]]\n",
    "n_original = len(FEATURE_COLUMNS) # Store original count here\n",
    "print(f\"Found {n_original} initial feature columns.\")\n",
    "print(f\"Target column: {TARGET_COLUMN}\")\n",
    "\n",
    "if not FEATURE_COLUMNS:\n",
    "    raise ValueError(\"No feature columns identified. Check IDENTIFIER_COLS and TARGET_COLUMN.\")\n",
    "if TARGET_COLUMN not in schema:\n",
    "     raise ValueError(f\"Target column '{TARGET_COLUMN}' not found in the dataset.\")\n",
    "\n",
    "# --- Step 1: Low Variance Threshold Preparation ---\n",
    "\n",
    "# 1a. Fit StandardScaler Incrementally on ALL original features\n",
    "print(\"\\n--- Step 1: Low Variance Threshold ---\")\n",
    "scaler = StandardScaler()\n",
    "print(f\"Fitting StandardScaler incrementally (batch size: {BATCH_SIZE})...\")\n",
    "selected_mask_variance = None # Initialize mask variable\n",
    "\n",
    "try:\n",
    "    total_rows = pl.scan_parquet(INPUT_FILE).select(pl.len()).collect().item()\n",
    "    n_batches = math.ceil(total_rows / BATCH_SIZE)\n",
    "    row_iterator = pl.read_parquet(INPUT_FILE, columns=FEATURE_COLUMNS).iter_slices(n_rows=BATCH_SIZE)\n",
    "\n",
    "    for i, data_chunk_pl in enumerate(tqdm(row_iterator, total=n_batches, desc=\"Fitting Scaler\")):\n",
    "        if data_chunk_pl.height > 0:\n",
    "            features_np = data_chunk_pl.to_numpy()\n",
    "            if features_np.size > 0:\n",
    "                # Check for NaNs/Infs which cause issues in partial_fit\n",
    "                if np.any(~np.isfinite(features_np)):\n",
    "                     print(f\"\\nWarning: Non-finite values found in chunk {i}. Replacing with 0 before scaling.\")\n",
    "                     features_np = np.nan_to_num(features_np, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "                scaler.partial_fit(features_np)\n",
    "            del features_np\n",
    "        del data_chunk_pl\n",
    "        gc.collect()\n",
    "\n",
    "    print(\"StandardScaler fitting complete.\")\n",
    "    joblib.dump(scaler, OUTPUT_SCALER_MODEL)\n",
    "    print(f\"Saved fitted scaler to {OUTPUT_SCALER_MODEL}\")\n",
    "\n",
    "    # 1b. Determine Variance Threshold Mask (based on the fitted scaler)\n",
    "    if not hasattr(scaler, 'var_') or scaler.var_ is None:\n",
    "        raise ValueError(\"Scaler variance (var_) attribute not found or is None. Fitting likely failed.\")\n",
    "\n",
    "    variances = scaler.var_\n",
    "    selector_variance = VarianceThreshold(threshold=VARIANCE_THRESHOLD)\n",
    "    selected_mask_variance = variances > VARIANCE_THRESHOLD # This mask corresponds to ORIGINAL features\n",
    "    features_after_variance = [\n",
    "        feature for feature, selected in zip(FEATURE_COLUMNS, selected_mask_variance) if selected\n",
    "    ]\n",
    "    n_after_variance = len(features_after_variance)\n",
    "\n",
    "    print(f\"Applied Variance Threshold > {VARIANCE_THRESHOLD}\")\n",
    "    print(f\"Features remaining after variance check: {n_after_variance} (removed {n_original - n_after_variance})\")\n",
    "\n",
    "    if not features_after_variance:\n",
    "        print(\"Error: No features remaining after variance thresholding. Check threshold or data.\")\n",
    "        exit(1)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during StandardScaler fitting or Variance Threshold prep: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit(1)\n",
    "\n",
    "\n",
    "# --- Step 2: Univariate Selection (Mutual Information) ---\n",
    "print(\"\\n--- Step 2: Mutual Information Selection ---\")\n",
    "features_after_mi = [] # Initialize final list\n",
    "n_after_mi = 0\n",
    "k_features = 0 # Initialize k_features\n",
    "\n",
    "# 2a. Sample Data (including ALL original features needed for scaling)\n",
    "print(f\"Sampling data ({MI_SAMPLE_SIZE} rows) for MI calculation...\")\n",
    "# We need all original features for scaling, plus the target\n",
    "cols_to_sample = FEATURE_COLUMNS + [TARGET_COLUMN]\n",
    "\n",
    "try:\n",
    "    if total_rows <= MI_SAMPLE_SIZE:\n",
    "         print(\"Total rows <= sample size, using all data for MI.\")\n",
    "         sample_df = pl.read_parquet(INPUT_FILE, columns=cols_to_sample)\n",
    "    else:\n",
    "        sample_df = pl.scan_parquet(INPUT_FILE, columns=cols_to_sample)\\\n",
    "                       .sample(n=MI_SAMPLE_SIZE, shuffle=True, seed=42)\\\n",
    "                       .collect()\n",
    "\n",
    "    print(f\"Sampled {sample_df.height} rows.\")\n",
    "    if sample_df.is_empty(): raise ValueError(\"Sampled DataFrame is empty.\")\n",
    "\n",
    "    # Separate features and target\n",
    "    X_sample_full = sample_df.select(FEATURE_COLUMNS).to_numpy() # Has n_original columns\n",
    "    y_sample_raw = sample_df.select(TARGET_COLUMN).to_numpy().ravel()\n",
    "    del sample_df\n",
    "    gc.collect()\n",
    "\n",
    "    # Encode target variable\n",
    "    le = LabelEncoder()\n",
    "    y_sample = le.fit_transform(y_sample_raw)\n",
    "    print(f\"Encoded target variable. Found classes: {le.classes_}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during data sampling: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit(1)\n",
    "\n",
    "# 2b. Scale the FULL Sample Data\n",
    "print(\"Scaling the sample data (using all original features)...\")\n",
    "try:\n",
    "    # Check for NaNs/Infs before transform\n",
    "    if np.any(~np.isfinite(X_sample_full)):\n",
    "         print(\"Warning: Non-finite values found in sample features. Replacing with 0 before transform.\")\n",
    "         X_sample_full = np.nan_to_num(X_sample_full, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    X_sample_scaled_full = scaler.transform(X_sample_full) # Transform uses the fitted scaler\n",
    "    del X_sample_full # Free memory\n",
    "    gc.collect()\n",
    "\n",
    "    # 2c. Apply Variance Threshold filtering to the SCALED sample data\n",
    "    print(\"Applying variance threshold filter to scaled sample data...\")\n",
    "    if selected_mask_variance is None:\n",
    "         raise ValueError(\"Variance threshold mask was not calculated.\")\n",
    "    # Use the mask calculated in step 1b to select columns from the scaled data\n",
    "    X_sample_scaled_variance_filtered = X_sample_scaled_full[:, selected_mask_variance]\n",
    "    del X_sample_scaled_full # Free memory\n",
    "    gc.collect()\n",
    "    print(f\"Shape of data for MI: {X_sample_scaled_variance_filtered.shape}\") # Should have n_after_variance columns\n",
    "\n",
    "except Exception as e:\n",
    "     print(f\"Error scaling sample data or applying variance filter: {e}\")\n",
    "     traceback.print_exc()\n",
    "     exit(1)\n",
    "\n",
    "\n",
    "# 2d. Calculate Mutual Information Scores and Select K Best\n",
    "print(f\"Calculating Mutual Information scores and selecting top {MI_SELECT_K} features...\")\n",
    "try:\n",
    "    # Check if input data for MI exists and has expected shape\n",
    "    if 'X_sample_scaled_variance_filtered' not in locals() or X_sample_scaled_variance_filtered.shape[1] != n_after_variance:\n",
    "         raise ValueError(\"Data for MI calculation is missing or has incorrect shape.\")\n",
    "\n",
    "    # Ensure k is not larger than the number of features available AFTER variance thresholding\n",
    "    num_features_for_mi = X_sample_scaled_variance_filtered.shape[1]\n",
    "    k_features = min(MI_SELECT_K, num_features_for_mi) # Define k_features here\n",
    "    if k_features < MI_SELECT_K:\n",
    "        print(f\"Warning: Requested K={MI_SELECT_K}, but only {k_features} available after variance threshold. Selecting all {k_features}.\")\n",
    "    if k_features == 0:\n",
    "        raise ValueError(\"k_features is 0, cannot select features.\")\n",
    "\n",
    "    # Use random_state for reproducibility if MI uses it\n",
    "    selector_mi = SelectKBest(lambda X, y: mutual_info_classif(X, y, discrete_features=False, random_state=42), k=k_features)\n",
    "    selector_mi.fit(X_sample_scaled_variance_filtered, y_sample)\n",
    "\n",
    "    # Get the mask relative to the variance-filtered features\n",
    "    selected_mask_mi = selector_mi.get_support()\n",
    "\n",
    "    # Map this mask back to the original feature names that passed the variance threshold\n",
    "    features_after_mi = [\n",
    "        feature for feature, selected in zip(features_after_variance, selected_mask_mi) if selected\n",
    "    ]\n",
    "    n_after_mi = len(features_after_mi)\n",
    "\n",
    "    print(\"Mutual Information selection complete.\")\n",
    "    print(f\"Final features selected: {n_after_mi} (removed {n_after_variance - n_after_mi} based on MI)\")\n",
    "\n",
    "    if n_after_mi == 0 :\n",
    "        print(\"Warning: Mutual information selected 0 features.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during Mutual Information calculation/selection: {e}\")\n",
    "    traceback.print_exc()\n",
    "    # No exit here, allow summary to print if possible, but feature list might be empty\n",
    "\n",
    "\n",
    "# --- Final Results ---\n",
    "print(\"\\n--- Feature Selection Summary ---\")\n",
    "print(f\"Initial features: {n_original}\")\n",
    "print(f\"After Variance Threshold (> {VARIANCE_THRESHOLD}): {n_after_variance}\")\n",
    "# Check if MI step completed successfully enough to have n_after_mi and k_features\n",
    "if 'n_after_mi' in locals() and 'k_features' in locals():\n",
    "    print(f\"After Mutual Information (Top {k_features}): {n_after_mi}\")\n",
    "else:\n",
    "    print(\"Mutual Information step did not complete successfully.\")\n",
    "\n",
    "# Save the final list of selected features\n",
    "if features_after_mi: # Only save if the list is not empty\n",
    "    try:\n",
    "        joblib.dump(features_after_mi, OUTPUT_FINAL_FEATURE_LIST)\n",
    "        print(f\"\\nSaved the final list of {n_after_mi} selected features to: {OUTPUT_FINAL_FEATURE_LIST}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving the final feature list: {e}\")\n",
    "else:\n",
    "    print(\"\\nNo features selected by Mutual Information, final list not saved.\")\n",
    "\n",
    "print(\"\\nFeature selection process finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading selected features from: final_selected_features_500.joblib\n",
      "Loaded 500 selected features.\n",
      "\n",
      "Loading data from: ML_dataset_500_features.parquet (Cols: 501)\n",
      "Loaded DataFrame shape: (2772, 501)\n",
      "Converted data to NumPy arrays.\n",
      "\n",
      "Encoding target variable...\n",
      "Target classes: ['Left' 'Right']\n",
      "Positive class 'Right' encoded as: 1\n",
      "Encoded target shape: (2772,)\n",
      "\n",
      "Splitting data into Training (75%) and Testing (25%)...\n",
      "X_train shape: (2079, 500), y_train shape: (2079,)\n",
      "X_test shape: (693, 500), y_test shape: (693,)\n",
      "\n",
      "Scaling features (fitting scaler on training data only)...\n",
      "Scaling complete.\n",
      "Saved fitted scaler to: trained_models_in_memory/scaler_in_memory.joblib\n",
      "\n",
      "Initializing models...\n",
      "\n",
      "--- Training, Evaluating Models, and Calculating Tuned Metrics ---\n",
      "\n",
      "--- Processing Model: LogisticRegression ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for LogisticRegression: X has 500 features, but LogisticRegression is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): LogisticRegression ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: SGDClassifier_Log ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for SGDClassifier_Log: X has 500 features, but SGDClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): SGDClassifier_Log ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: SVC_Linear ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for SVC_Linear: X has 500 features, but SVC is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): SVC_Linear ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: SVC_RBF ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for SVC_RBF: X has 500 features, but SVC is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): SVC_RBF ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: RandomForest ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for RandomForest: X has 500 features, but RandomForestClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): RandomForest ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: GradientBoosting ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for GradientBoosting: X has 500 features, but GradientBoostingClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): GradientBoosting ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: KNeighbors ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for KNeighbors: X has 500 features, but KNeighborsClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): KNeighbors ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: GaussianNB ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for GaussianNB: X has 500 features, but GaussianNB is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): GaussianNB ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: DecisionTree ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for DecisionTree: X has 500 features, but DecisionTreeClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): DecisionTree ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Processing Model: MLPClassifier ---\n",
      "Loaded trained model.\n",
      "Could not generate probabilities for MLPClassifier: X has 500 features, but MLPClassifier is expecting 200 features as input.\n",
      "\n",
      "--- Evaluation Results (Tuned Threshold): MLPClassifier ---\n",
      "Tuning skipped or failed. No tuned metrics to display.\n",
      "----------------------------------------\n",
      "\n",
      "--- Final Tuned Metrics Summary ---\n",
      "Model                     | Best Threshold  | Accuracy   | Precision  | Recall     | F1 Score   | ROC AUC   \n",
      "---------------------------------------------------------------------------------------------------------\n",
      "LogisticRegression        | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "SGDClassifier_Log         | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "SVC_Linear                | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "SVC_RBF                   | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "RandomForest              | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "GradientBoosting          | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "KNeighbors                | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "GaussianNB                | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "DecisionTree              | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "MLPClassifier             | N/A             | N/A        | N/A        | N/A        | N/A        | N/A       \n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "import gc # Import gc for memory management\n",
    "import traceback # Import traceback for error details\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Import popular classifiers\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Suppress convergence warnings for models like Logistic Regression or MLP\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn')\n",
    "\n",
    "# --- Configuration ---\n",
    "INPUT_FEATURES_FILE = \"ML_dataset_500_features.parquet\" # The dataset with ~4k features\n",
    "SELECTED_FEATURES_LIST_FILE = \"final_selected_features_500.joblib\" # List of ~500 feature names\n",
    "TARGET_COLUMN = \"marker\"\n",
    "IDENTIFIER_COLS = ['event_id', 'prev_marker'] # Columns to ignore for features/target\n",
    "\n",
    "TEST_SIZE = 0.25\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "OUTPUT_MODEL_DIR = \"trained_models_in_memory\"\n",
    "os.makedirs(OUTPUT_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "# --- 1. Load Selected Features ---\n",
    "print(f\"Loading selected features from: {SELECTED_FEATURES_LIST_FILE}\")\n",
    "try:\n",
    "    selected_features = joblib.load(SELECTED_FEATURES_LIST_FILE)\n",
    "    if not isinstance(selected_features, list) or len(selected_features) == 0:\n",
    "        raise ValueError(\"Loaded features are not a valid non-empty list.\")\n",
    "    print(f\"Loaded {len(selected_features)} selected features.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Selected features file not found at {SELECTED_FEATURES_LIST_FILE}\")\n",
    "    exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading selected features: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "columns_to_load = selected_features + [TARGET_COLUMN]\n",
    "\n",
    "# --- 2. Load Dataset into Memory ---\n",
    "print(f\"\\nLoading data from: {INPUT_FEATURES_FILE} (Cols: {len(columns_to_load)})\")\n",
    "try:\n",
    "    if not os.path.exists(INPUT_FEATURES_FILE):\n",
    "        raise FileNotFoundError(f\"Input file not found: {INPUT_FEATURES_FILE}\")\n",
    "    df_pl = pl.read_parquet(INPUT_FEATURES_FILE, columns=columns_to_load)\n",
    "    print(f\"Loaded DataFrame shape: {df_pl.shape}\")\n",
    "\n",
    "    X = df_pl.select(selected_features).to_numpy()\n",
    "    y_raw = df_pl.select(TARGET_COLUMN).to_numpy().ravel()\n",
    "    del df_pl\n",
    "    gc.collect()\n",
    "    print(\"Converted data to NumPy arrays.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "     print(f\"Error: Input file not found at {INPUT_FEATURES_FILE}\")\n",
    "     exit(1)\n",
    "except pl.exceptions.ColumnNotFoundError as e:\n",
    "     print(f\"Error: One or more selected columns not found in {INPUT_FEATURES_FILE}. Details: {e}\")\n",
    "     print(\"Ensure the feature list file corresponds to the columns in the Parquet file.\")\n",
    "     exit(1)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading or processing data: {e}\")\n",
    "    traceback.print_exc()\n",
    "    exit(1)\n",
    "\n",
    "# --- 3. Handle Missing Values ---\n",
    "if np.any(~np.isfinite(X)):\n",
    "    print(\"Warning: Non-finite values (NaN/Inf) found in features. Replacing with 0.\")\n",
    "    X = np.nan_to_num(X, nan=0.0, posinf=np.finfo(X.dtype).max, neginf=np.finfo(X.dtype).min)\n",
    "\n",
    "# --- 4. Encode Target Variable ---\n",
    "print(\"\\nEncoding target variable...\")\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y_raw)\n",
    "print(f\"Target classes: {label_encoder.classes_}\")\n",
    "# Find index of the 'positive' class (e.g., 'Right', assuming it's the second class)\n",
    "positive_class_label = 'Right' # Or 'Left', choose one consistently\n",
    "try:\n",
    "    positive_class_index = np.where(label_encoder.classes_ == positive_class_label)[0][0]\n",
    "    print(f\"Positive class '{positive_class_label}' encoded as: {positive_class_index}\")\n",
    "except IndexError:\n",
    "    print(f\"Warning: Positive class label '{positive_class_label}' not found in target classes. Using default index 1.\")\n",
    "    positive_class_index = 1 # Default to 1 if not found\n",
    "\n",
    "print(f\"Encoded target shape: {y.shape}\")\n",
    "\n",
    "# --- 5. Split Data into Train/Test ---\n",
    "print(f\"\\nSplitting data into Training ({1-TEST_SIZE:.0%}) and Testing ({TEST_SIZE:.0%})...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "del X, y_raw, y # Free up memory after splitting\n",
    "gc.collect()\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 6. Scale Features ---\n",
    "print(\"\\nScaling features (fitting scaler on training data only)...\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test) # Scale X_test here once after loading\n",
    "print(\"Scaling complete.\")\n",
    "scaler_path = os.path.join(OUTPUT_MODEL_DIR, \"scaler_in_memory.joblib\")\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"Saved fitted scaler to: {scaler_path}\")\n",
    "# Keep X_train_scaled for training within this script\n",
    "\n",
    "\n",
    "# --- 7. Initialize Models ---\n",
    "print(\"\\nInitializing models...\")\n",
    "# Ensure models that need probability=True have it set\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=RANDOM_STATE, max_iter=1000, solver='liblinear'),\n",
    "    \"SGDClassifier_Log\": SGDClassifier(loss='log_loss', random_state=RANDOM_STATE, max_iter=1000, tol=1e-3), # Supports predict_proba\n",
    "    # SGDClassifier_Hinge does NOT support predict_proba directly\n",
    "    \"SVC_Linear\": SVC(kernel='linear', probability=True, random_state=RANDOM_STATE), # Needs probability=True\n",
    "    \"SVC_RBF\": SVC(kernel='rbf', probability=True, random_state=RANDOM_STATE),       # Needs probability=True\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=150, random_state=RANDOM_STATE, n_jobs=-1, max_depth=20, min_samples_leaf=5),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=100, random_state=RANDOM_STATE, learning_rate=0.1, max_depth=3), # Supports predict_proba\n",
    "    \"KNeighbors\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1), # Supports predict_proba\n",
    "    \"GaussianNB\": GaussianNB(), # Supports predict_proba\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=RANDOM_STATE, max_depth=15, min_samples_leaf=10), # Supports predict_proba\n",
    "    \"MLPClassifier\": MLPClassifier(hidden_layer_sizes=(64, 32), random_state=RANDOM_STATE, max_iter=500, early_stopping=True) # Supports predict_proba\n",
    "}\n",
    "\n",
    "# --- Helper Function for Threshold Tuning ---\n",
    "def find_best_threshold(y_true, y_pred_proba, steps=100):\n",
    "    \"\"\"Finds the probability threshold that maximizes accuracy.\"\"\"\n",
    "    best_threshold = 0.5 # Default starting point\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Ensure probabilities are within [0, 1] and handle potential edge cases\n",
    "    y_pred_proba = np.clip(y_pred_proba, 0.0, 1.0)\n",
    "\n",
    "    # Define a range of thresholds to check. Include 0 and 1 explicitly.\n",
    "    # Add small epsilon to avoid issues with floating point comparisons at 0 and 1\n",
    "    thresholds = np.linspace(np.min(y_pred_proba) - 1e-6, np.max(y_pred_proba) + 1e-6, steps + 1)\n",
    "    thresholds = np.clip(thresholds, 0.0, 1.0) # Ensure thresholds are within [0, 1]\n",
    "    thresholds = np.unique(thresholds) # Use unique thresholds\n",
    "\n",
    "    # Calculate initial accuracy with default threshold 0.5 if it's a valid probability\n",
    "    if 0.5 >= np.min(y_pred_proba) and 0.5 <= np.max(y_pred_proba):\n",
    "         y_pred_default = (y_pred_proba >= 0.5).astype(int)\n",
    "         best_accuracy = accuracy_score(y_true, y_pred_default)\n",
    "         best_threshold = 0.5 # Start with 0.5 if it's in the range of predictions\n",
    "\n",
    "\n",
    "    # Iterate through other thresholds\n",
    "    # Using tqdm for the threshold search loop as it can be time-consuming\n",
    "    for threshold in thresholds:\n",
    "        y_pred_tuned = (y_pred_proba >= threshold).astype(int)\n",
    "        current_accuracy = accuracy_score(y_true, y_pred_tuned)\n",
    "        if current_accuracy > best_accuracy:\n",
    "            best_accuracy = current_accuracy\n",
    "            best_threshold = threshold\n",
    "\n",
    "    return best_threshold, best_accuracy\n",
    "\n",
    "# --- 8. Train, Save, Evaluate, and Calculate Tuned Metrics ---\n",
    "print(\"\\n--- Training, Saving, Evaluating Models, and Calculating Tuned Metrics ---\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "# Train and save models first\n",
    "print(\"\\n--- Training Models ---\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Training Model: {name}...\")\n",
    "    try:\n",
    "        # Train the model using the scaled training data\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        print(f\"Training complete for {name}.\")\n",
    "\n",
    "        # Save the trained model\n",
    "        model_path = os.path.join(OUTPUT_MODEL_DIR, f\"{name}.joblib\")\n",
    "        joblib.dump(model, model_path)\n",
    "        print(f\"Saved trained model to: {model_path}\")\n",
    "\n",
    "    except MemoryError:\n",
    "         print(f\"MemoryError occurred while training {name}.\")\n",
    "         results[name] = {'status': 'Training MemoryError'}\n",
    "         # Optionally, try to save an indication of failure\n",
    "         fail_path = os.path.join(OUTPUT_MODEL_DIR, f\"{name}_train_failed.txt\")\n",
    "         with open(fail_path, 'w') as f:\n",
    "             f.write('MemoryError during training')\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while training {name}: {e}\")\n",
    "        results[name] = {'status': f'Training Error: {e}'}\n",
    "        traceback.print_exc()\n",
    "        fail_path = os.path.join(OUTPUT_MODEL_DIR, f\"{name}_train_failed.txt\")\n",
    "        with open(fail_path, 'w') as f:\n",
    "            f.write(f'Error during training: {e}')\n",
    "\n",
    "\n",
    "# Clear training data from memory to free up space for evaluation\n",
    "del X_train_scaled, y_train\n",
    "gc.collect()\n",
    "print(\"\\nFinished training all models and cleared training data.\")\n",
    "\n",
    "# Evaluate models and tune thresholds\n",
    "print(\"\\n--- Evaluating Models and Calculating Tuned Metrics ---\")\n",
    "# X_test_scaled and y_test should still be in memory or reloaded if needed\n",
    "\n",
    "for name, model in models.items(): # Iterate through models again for evaluation\n",
    "    print(f\"\\n--- Processing Model for Evaluation: {name} ---\")\n",
    "    model_path = os.path.join(OUTPUT_MODEL_DIR, f\"{name}.joblib\")\n",
    "    fail_path = os.path.join(OUTPUT_MODEL_DIR, f\"{name}_train_failed.txt\")\n",
    "\n",
    "    if not os.path.exists(model_path):\n",
    "         if os.path.exists(fail_path):\n",
    "             print(f\"Training failed for {name}. Skipping evaluation.\")\n",
    "             continue # Skip evaluation if training failed\n",
    "         else:\n",
    "            print(f\"Trained model file not found for {name} at {model_path}. Skipping evaluation.\")\n",
    "            results[name] = {'status': 'Trained Model File Not Found'}\n",
    "            continue # Skip to the next model\n",
    "\n",
    "    try:\n",
    "        # Load the trained model\n",
    "        model = joblib.load(model_path)\n",
    "        print(\"Loaded trained model.\")\n",
    "\n",
    "        # Get predictions and probabilities\n",
    "        y_pred_proba = None\n",
    "        # For models that don't support predict_proba, we can still get binary predictions\n",
    "        # But threshold tuning and ROC AUC are not possible.\n",
    "        binary_predictions_default = None\n",
    "\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            try:\n",
    "                # Get probabilities for the positive class\n",
    "                # Ensure the model expects the current number of features (500)\n",
    "                # This implicitly checks if the loaded model matches the test data features\n",
    "                y_pred_proba = model.predict_proba(X_test_scaled)[:, positive_class_index]\n",
    "                print(\"Generated prediction probabilities.\")\n",
    "            except ValueError as ve:\n",
    "                 print(f\"Feature mismatch during predict_proba for {name}: {ve}. This model was likely trained on a different number of features.\")\n",
    "                 results[name] = {'status': f'Feature Mismatch Error: {ve}'}\n",
    "                 continue # Skip evaluation for this model\n",
    "            except Exception as pe:\n",
    "                print(f\"Could not generate probabilities for {name}: {pe}\")\n",
    "        elif hasattr(model, \"predict\"):\n",
    "             try:\n",
    "                 binary_predictions_default = model.predict(X_test_scaled)\n",
    "                 print(\"Generated binary predictions (predict_proba not supported).\")\n",
    "             except ValueError as ve:\n",
    "                 print(f\"Feature mismatch during predict for {name}: {ve}. This model was likely trained on a different number of features.\")\n",
    "                 results[name] = {'status': f'Feature Mismatch Error: {ve}'}\n",
    "                 continue # Skip evaluation for this model\n",
    "             except Exception as pe:\n",
    "                print(f\"Could not generate binary predictions for {name}: {pe}\")\n",
    "        else:\n",
    "            print(f\"Model {name} does not support predict_proba or predict. Skipping evaluation.\")\n",
    "            results[name] = {'status': 'Predict Methods Not Supported'}\n",
    "            continue\n",
    "\n",
    "\n",
    "        # --- Threshold Tuning and Tuned Metrics Calculation ---\n",
    "        best_threshold = 'N/A'\n",
    "        accuracy_tuned = 'N/A'\n",
    "        report_tuned = 'N/A'\n",
    "        cm_tuned = 'N/A'\n",
    "        precision_tuned = 'N/A'\n",
    "        recall_tuned = 'N/A'\n",
    "        f1_tuned = 'N/A'\n",
    "        roc_auc_tuned = 'N/A' # ROC AUC is calculated from probabilities, not binary predictions\n",
    "\n",
    "\n",
    "        if y_pred_proba is not None:\n",
    "            print(\"Tuning threshold based on Accuracy...\")\n",
    "            try:\n",
    "                best_threshold, accuracy_tuned = find_best_threshold(y_test, y_pred_proba)\n",
    "\n",
    "                # Calculate all metrics using the best_threshold\n",
    "                final_binary_predictions = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "                accuracy_tuned = accuracy_score(y_test, final_binary_predictions)\n",
    "                precision_tuned = precision_score(y_test, final_binary_predictions, zero_division=0)\n",
    "                recall_tuned = recall_score(y_test, final_binary_predictions, zero_division=0)\n",
    "                f1_tuned = f1_score(y_test, final_binary_predictions, zero_division=0)\n",
    "                cm_tuned = confusion_matrix(y_test, final_binary_predictions)\n",
    "                report_tuned = classification_report(y_test, final_binary_predictions, target_names=label_encoder.classes_, zero_division=0)\n",
    "\n",
    "                # ROC AUC is calculated from probabilities, before thresholding\n",
    "                roc_auc_tuned = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "                print(f\"Best threshold found: {best_threshold:.4f}\")\n",
    "                print(\"Calculated tuned metrics.\")\n",
    "\n",
    "            except Exception as te:\n",
    "                print(f\"Could not tune threshold or calculate tuned metrics for {name}: {te}\")\n",
    "                traceback.print_exc()\n",
    "                best_threshold = 'Error'\n",
    "                accuracy_tuned = 'Error'\n",
    "                report_tuned = 'Error'\n",
    "                cm_tuned = 'Error'\n",
    "                precision_tuned = 'Error'\n",
    "                recall_tuned = 'Error'\n",
    "                f1_tuned = 'Error'\n",
    "                roc_auc_tuned = 'Error' # Mark as error if probability calculation failed earlier\n",
    "\n",
    "        elif binary_predictions_default is not None:\n",
    "            # For models that don't support predict_proba, we just use the default predictions\n",
    "            print(\"Using default binary predictions (predict_proba not supported).\")\n",
    "            best_threshold = 'N/A (No Proba)'\n",
    "            final_binary_predictions = binary_predictions_default\n",
    "\n",
    "            accuracy_tuned = accuracy_score(y_test, final_binary_predictions)\n",
    "            precision_tuned = precision_score(y_test, final_binary_predictions, zero_division=0)\n",
    "            recall_tuned = recall_score(y_test, final_binary_predictions, zero_division=0)\n",
    "            f1_tuned = f1_score(y_test, final_binary_predictions, zero_division=0)\n",
    "            cm_tuned = confusion_matrix(y_test, final_binary_predictions)\n",
    "            report_tuned = classification_report(y_test, final_binary_predictions, target_names=label_encoder.classes_, zero_division=0)\n",
    "            roc_auc_tuned = 'N/A (No Proba)' # Cannot calculate ROC AUC without probabilities\n",
    "\n",
    "            print(\"Calculated metrics based on default predictions.\")\n",
    "\n",
    "\n",
    "        # Store results\n",
    "        results[name] = {\n",
    "            'best_threshold': best_threshold,\n",
    "            'accuracy_tuned': accuracy_tuned,\n",
    "            'precision_tuned': precision_tuned,\n",
    "            'recall_tuned': recall_tuned,\n",
    "            'f1_tuned': f1_tuned,\n",
    "            'roc_auc_tuned': roc_auc_tuned,\n",
    "            'report_tuned': report_tuned,\n",
    "            'cm_tuned': cm_tuned,\n",
    "            'status': 'Evaluated' if accuracy_tuned != 'Error' and accuracy_tuned != 'N/A' else 'Evaluation Failed'\n",
    "        }\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"\\n--- Evaluation Results: {name} ---\")\n",
    "        if results[name]['status'] == 'Evaluated':\n",
    "            print(f\"Best Threshold Found            : {best_threshold}\")\n",
    "            print(f\"Accuracy                      : {accuracy_tuned:.4f}\")\n",
    "            print(f\"Precision                     : {precision_tuned:.4f}\")\n",
    "            print(f\"Recall                        : {recall_tuned:.4f}\")\n",
    "            print(f\"F1 Score                      : {f1_tuned:.4f}\")\n",
    "            if roc_auc_tuned != 'N/A (No Proba)' and roc_auc_tuned != 'Error':\n",
    "                 print(f\"ROC AUC                       : {roc_auc_tuned:.4f}\")\n",
    "            print(\"\\nClassification Report:\")\n",
    "            print(report_tuned)\n",
    "            print(\"Confusion Matrix:\")\n",
    "            print(cm_tuned)\n",
    "        else:\n",
    "            print(f\"Evaluation skipped or failed: {results[name]['status']}\")\n",
    "\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "\n",
    "    except MemoryError:\n",
    "         print(f\"MemoryError occurred while evaluating {name}.\")\n",
    "         results[name] = {'status': 'Evaluation MemoryError'}\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while evaluating {name}: {e}\")\n",
    "        results[name] = {'status': f'Evaluation Error: {e}'}\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "# --- 9. Final Summary ---\n",
    "print(\"\\n--- Final Tuned Metrics Summary ---\")\n",
    "print(f\"{'Model':<25} | {'Best Threshold':<15} | {'Accuracy':<10} | {'Precision':<10} | {'Recall':<10} | {'F1 Score':<10} | {'ROC AUC':<10}\")\n",
    "print(\"-\" * 105)\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    status = metrics.get('status', 'Unknown') # Use get to handle cases where status might not be set\n",
    "\n",
    "    if status == 'Evaluated':\n",
    "        thresh_str = f\"{metrics['best_threshold']:.4f}\" if isinstance(metrics['best_threshold'], float) else str(metrics['best_threshold'])\n",
    "        acc_str = f\"{metrics['accuracy_tuned']:.4f}\" if isinstance(metrics['accuracy_tuned'], float) else str(metrics['accuracy_tuned'])\n",
    "        prec_str = f\"{metrics['precision_tuned']:.4f}\" if isinstance(metrics['precision_tuned'], float) else str(metrics['precision_tuned'])\n",
    "        rec_str = f\"{metrics['recall_tuned']:.4f}\" if isinstance(metrics['recall_tuned'], float) else str(metrics['recall_tuned'])\n",
    "        f1_str = f\"{metrics['f1_tuned']:.4f}\" if isinstance(metrics['f1_tuned'], float) else str(metrics['f1_tuned'])\n",
    "        roc_auc_str = f\"{metrics['roc_auc_tuned']:.4f}\" if isinstance(metrics['roc_auc_tuned'], float) else str(metrics['roc_auc_tuned'])\n",
    "\n",
    "        print(f\"{name:<25} | {thresh_str:<15} | {acc_str:<10} | {prec_str:<10} | {rec_str:<10} | {f1_str:<10} | {roc_auc_str:<10}\")\n",
    "    else:\n",
    "        print(f\"{name:<25} | {status:<15} | {'-':<10} | {'-':<10} | {'-':<10} | {'-':<10} | {'-':<10}\")\n",
    "\n",
    "print(\"-\" * 105)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
