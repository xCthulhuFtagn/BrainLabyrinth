{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import janitor\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "data_path = '/home/owner/Documents/DEV/BrainLabyrinth/data/Ymaze_exp'\n",
    "final_dataset_path = '/home/owner/Documents/DEV/BrainLabyrinth/data/final_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a3845302a3407786ec6a334792ea13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/53 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up high-pass filter at 0.1 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal highpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.10\n",
      "- Lower transition bandwidth: 0.10 Hz (-6 dB cutoff frequency: 0.05 Hz)\n",
      "- Filter length: 16501 samples (33.002 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 3301 samples (6.602 s)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m raw\u001b[38;5;241m.\u001b[39mfilter(l_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, h_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# High-pass filter (low-frequency cutoff at 0.1 Hz)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 3. Notch filter at 50 Hz (to remove power line noise)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mraw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotch_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Notch filter for 50 Hz\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 4. Detrend the data using scipy.signal.detrend\u001b[39;00m\n\u001b[1;32m     25\u001b[0m raw\u001b[38;5;241m.\u001b[39m_data \u001b[38;5;241m=\u001b[39m signal\u001b[38;5;241m.\u001b[39mdetrend(raw\u001b[38;5;241m.\u001b[39m_data, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Detrend along the time axis (axis=1)\u001b[39;00m\n",
      "File \u001b[0;32m<decorator-gen-202>:12\u001b[0m, in \u001b[0;36mnotch_filter\u001b[0;34m(self, freqs, picks, filter_length, notch_widths, trans_bandwidth, n_jobs, method, iir_params, mt_bandwidth, p_value, phase, fir_window, fir_design, pad, skip_by_annotation, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/io/base.py:1283\u001b[0m, in \u001b[0;36mBaseRaw.notch_filter\u001b[0;34m(self, freqs, picks, filter_length, notch_widths, trans_bandwidth, n_jobs, method, iir_params, mt_bandwidth, p_value, phase, fir_window, fir_design, pad, skip_by_annotation, verbose)\u001b[0m\n\u001b[1;32m   1279\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltering raw data in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m contiguous segment\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(onsets), _pl(onsets)\n\u001b[1;32m   1281\u001b[0m )\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m si, (start, stop) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(onsets, ends)):\n\u001b[0;32m-> 1283\u001b[0m     \u001b[43mnotch_filter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnotch_widths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnotch_widths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrans_bandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrans_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmt_bandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmt_bandwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m<decorator-gen-109>:12\u001b[0m, in \u001b[0;36mnotch_filter\u001b[0;34m(x, Fs, freqs, filter_length, notch_widths, trans_bandwidth, method, iir_params, mt_bandwidth, p_value, picks, n_jobs, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/filter.py:1550\u001b[0m, in \u001b[0;36mnotch_filter\u001b[0;34m(x, Fs, freqs, filter_length, notch_widths, trans_bandwidth, method, iir_params, mt_bandwidth, p_value, picks, n_jobs, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1548\u001b[0m     lows \u001b[38;5;241m=\u001b[39m [freq \u001b[38;5;241m-\u001b[39m nw \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m-\u001b[39m tb_2 \u001b[38;5;28;01mfor\u001b[39;00m freq, nw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(freqs, notch_widths)]\n\u001b[1;32m   1549\u001b[0m     highs \u001b[38;5;241m=\u001b[39m [freq \u001b[38;5;241m+\u001b[39m nw \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m \u001b[38;5;241m+\u001b[39m tb_2 \u001b[38;5;28;01mfor\u001b[39;00m freq, nw \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(freqs, notch_widths)]\n\u001b[0;32m-> 1550\u001b[0m     xf \u001b[38;5;241m=\u001b[39m \u001b[43mfilter_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m        \u001b[49m\u001b[43mFs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhighs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1560\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1561\u001b[0m \u001b[43m        \u001b[49m\u001b[43miir_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1563\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_window\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfir_design\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspectrum_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1569\u001b[0m     xf \u001b[38;5;241m=\u001b[39m _mt_spectrum_proc(\n\u001b[1;32m   1570\u001b[0m         x,\n\u001b[1;32m   1571\u001b[0m         Fs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1579\u001b[0m         filter_length,\n\u001b[1;32m   1580\u001b[0m     )\n",
      "File \u001b[0;32m<decorator-gen-107>:12\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/filter.py:1027\u001b[0m, in \u001b[0;36mfilter_data\u001b[0;34m(data, sfreq, l_freq, h_freq, picks, filter_length, l_trans_bandwidth, h_trans_bandwidth, n_jobs, method, iir_params, copy, phase, fir_window, fir_design, pad, verbose)\u001b[0m\n\u001b[1;32m   1012\u001b[0m filt \u001b[38;5;241m=\u001b[39m create_filter(\n\u001b[1;32m   1013\u001b[0m     data,\n\u001b[1;32m   1014\u001b[0m     sfreq,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     fir_design,\n\u001b[1;32m   1025\u001b[0m )\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfir\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1027\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_overlap_add_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1029\u001b[0m     data \u001b[38;5;241m=\u001b[39m _iir_filter(data, filt, picks, n_jobs, copy, phase)\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/filter.py:346\u001b[0m, in \u001b[0;36m_overlap_add_filter\u001b[0;34m(x, h, n_fft, phase, picks, n_jobs, copy, pad)\u001b[0m\n\u001b[1;32m    342\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m _1d_overlap_filter(\n\u001b[1;32m    343\u001b[0m             x[p], \u001b[38;5;28mlen\u001b[39m(h), n_edge, phase, cuda_dict, pad, n_fft\n\u001b[1;32m    344\u001b[0m         )\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 346\u001b[0m     data_new \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mp_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_edge\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pp, p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(picks):\n\u001b[1;32m    350\u001b[0m         x[p] \u001b[38;5;241m=\u001b[39m data_new[pp]\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/parallel.py:127\u001b[0m, in \u001b[0;36mparallel_func.<locals>.run_verbose\u001b[0;34m(verbose, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_verbose\u001b[39m(\u001b[38;5;241m*\u001b[39margs, verbose\u001b[38;5;241m=\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlevel, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m use_log_level(verbose\u001b[38;5;241m=\u001b[39mverbose):\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/filter.py:375\u001b[0m, in \u001b[0;36m_1d_overlap_filter\u001b[0;34m(x, n_h, n_edge, phase, cuda_dict, pad, n_fft)\u001b[0m\n\u001b[1;32m    372\u001b[0m seg \u001b[38;5;241m=\u001b[39m x_ext[start:stop]\n\u001b[1;32m    373\u001b[0m seg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([seg, np\u001b[38;5;241m.\u001b[39mzeros(n_fft \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(seg))])\n\u001b[0;32m--> 375\u001b[0m prod \u001b[38;5;241m=\u001b[39m \u001b[43m_fft_multiply_repeated\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m start_filt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, start \u001b[38;5;241m-\u001b[39m shift)\n\u001b[1;32m    378\u001b[0m stop_filt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(start \u001b[38;5;241m-\u001b[39m shift \u001b[38;5;241m+\u001b[39m n_fft, n_x)\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/mne/cuda.py:217\u001b[0m, in \u001b[0;36m_fft_multiply_repeated\u001b[0;34m(x, cuda_dict)\u001b[0m\n\u001b[1;32m    215\u001b[0m x_fft \u001b[38;5;241m=\u001b[39m cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrfft\u001b[39m\u001b[38;5;124m\"\u001b[39m](x, cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    216\u001b[0m x_fft \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m cuda_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_fft\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 217\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mirfft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_fft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcuda_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_fft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/scipy/fft/_backend.py:28\u001b[0m, in \u001b[0;36m_ScipyBackend.__ua_function__\u001b[0;34m(method, args, kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/scipy/fft/_basic_backend.py:80\u001b[0m, in \u001b[0;36mirfft\u001b[0;34m(x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mirfft\u001b[39m(x, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     79\u001b[0m           overwrite_x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, plan\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_execute_1D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mirfft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pocketfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mirfft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/scipy/fft/_basic_backend.py:29\u001b[0m, in \u001b[0;36m_execute_1D\u001b[0;34m(func_str, pocketfft_func, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_numpy(xp):\n\u001b[1;32m     28\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\n\u001b[0;32m---> 29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpocketfft_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                          \u001b[49m\u001b[43moverwrite_x\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m norm \u001b[38;5;241m=\u001b[39m _validate_fft_args(workers, plan, norm)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(xp, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfft\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/scipy/fft/_pocketfft/basic.py:95\u001b[0m, in \u001b[0;36mc2r\u001b[0;34m(forward, x, n, axis, norm, overwrite_x, workers, plan)\u001b[0m\n\u001b[1;32m     92\u001b[0m     tmp, _ \u001b[38;5;241m=\u001b[39m _fix_shape_1d(tmp, (n\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, axis)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m# Note: overwrite_x is not utilized\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpfft\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc2r\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# from sklearn.decomposition import PCA as sklearnPCA\n",
    "import scipy.signal as signal\n",
    "\n",
    "for user_id in tqdm(os.listdir(data_path)):\n",
    "    person_dir = os.path.join(data_path, user_id)\n",
    "    for file in os.listdir(person_dir):\n",
    "        file_path = os.path.join(person_dir, file)\n",
    "\n",
    "        if file.endswith(\".vhdr\"):\n",
    "            # Read the EEG data\n",
    "            raw = mne.io.read_raw_brainvision(file_path, preload=True, ignore_marker_types=True, verbose=False)\n",
    "            \n",
    "            # Apply preprocessing steps\n",
    "\n",
    "            # 1. Resample to 500 Hz\n",
    "            raw.resample(500, npad=\"auto\")  # Resample to 500 Hz\n",
    "            \n",
    "            # 2. Filter high-pass at 0.1 Hz (for low-frequency noise removal)\n",
    "            raw.filter(l_freq=0.1, h_freq=None)  # High-pass filter (low-frequency cutoff at 0.1 Hz)\n",
    "            \n",
    "            # 3. Notch filter at 50 Hz (to remove power line noise)\n",
    "            raw.notch_filter(freqs=50, picks='all')  # Notch filter for 50 Hz\n",
    "\n",
    "            # 4. Detrend the data using scipy.signal.detrend\n",
    "            raw._data = signal.detrend(raw._data, axis=1)  # Detrend along the time axis (axis=1)\n",
    "\n",
    "            # 5. Apply PCA for dimensionality reduction (if necessary)\n",
    "            # n_components = 20\n",
    "            # pca = sklearnPCA(n_components=n_components)\n",
    "            # data_pca = pca.fit_transform(raw.get_data())  # Apply PCA to the EEG data\n",
    "            # raw._data = data_pca  # Replace the original data with the PCA-transformed data\n",
    "            \n",
    "            # Continue with the rest of your pipeline as you have it\n",
    "            # Find the corresponding .vmrk file\n",
    "            vmrk_file = file.replace('.vhdr', '.vmrk')\n",
    "            vmrk_file_path = os.path.join(person_dir, vmrk_file)\n",
    "\n",
    "            if os.path.exists(vmrk_file_path):\n",
    "                # Read the annotations (markers) from the .vmrk file\n",
    "                annotations = mne.annotations.read_annotations(vmrk_file_path)\n",
    "            # Convert raw data to DataFrame\n",
    "            time_series = raw.to_data_frame()\n",
    "\n",
    "            # Extract markers (annotations)\n",
    "            marker_times = annotations.onset  # In seconds\n",
    "            marker_labels = annotations.description  # The marker labels\n",
    "\n",
    "            # Create a DataFrame for the markers\n",
    "            markers_df = pd.DataFrame({\n",
    "                'event_id': np.arange(len(marker_labels)), \n",
    "                'start': marker_times - 3.0,\n",
    "                'end': marker_times + 1.0,\n",
    "                'marker': marker_labels\n",
    "            })\n",
    "            \n",
    "            markers_df = markers_df[\n",
    "                ~markers_df.marker.isin([\n",
    "                    'Marker/Impedance', 'New Segment/', 'Stimulus/2'\n",
    "                ])\n",
    "            ]\n",
    "            # markers_df.marker = markers_df.marker.replace({'Stimulus/2': 'Stimulus/P'})\n",
    "\n",
    "            # Display the first few rows of both DataFrames\n",
    "            # Merge markers with EEG data\n",
    "            time_series['time'] = time_series['time'].round(3)  # Round times to 3 decimal places for matching\n",
    "\n",
    "            merged_df = janitor.conditional_join(\n",
    "                markers_df, \n",
    "                time_series,\n",
    "                ('start', 'time', '<='),\n",
    "                ('end', 'time', '>='),\n",
    "                how='left',\n",
    "                df_columns=['event_id', 'marker']\n",
    "            )\n",
    "            # display(merged_df.groupby('event_id').count())\n",
    "            merged_path = os.path.join(final_dataset_path, f\"{user_id}.parquet\")\n",
    "            merged_df.to_parquet(merged_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   event_id      marker    time        Fp1        Fpz        Fp2         F7  \\\n",
      "0         0  Stimulus/P  23.620  18.929390  27.035186  26.474021 -37.195889   \n",
      "1         0  Stimulus/P  23.622  21.587595  26.084012  25.872122 -34.220734   \n",
      "2         0  Stimulus/P  23.624  22.985251  22.778513  20.055913 -32.408453   \n",
      "3         0  Stimulus/P  23.626  26.445074  26.938968  21.746364 -29.977234   \n",
      "4         0  Stimulus/P  23.628  27.858514  33.056260  30.219951 -27.094996   \n",
      "\n",
      "         F3         Fz         F4  ...        PO3        PO4       PO6  \\\n",
      "0  8.102022  26.115237  13.509483  ... -13.759602  -6.662856 -7.093113   \n",
      "1  2.335635  25.532525  17.738738  ... -15.645522  -9.955678 -9.481412   \n",
      "2  1.843952  23.887538  14.971009  ...  -7.170127 -12.647842 -9.841793   \n",
      "3  6.261537  25.611078  17.984585  ... -13.886536 -11.800133 -9.656715   \n",
      "4  9.726444  30.116939  19.419637  ... -27.232310 -10.963815 -8.354059   \n",
      "\n",
      "         FT7       FT8        TP7        TP8        PO7        PO8         Oz  \n",
      "0 -14.274561 -5.782883 -20.014128  11.247635   5.061285  -6.010722 -10.334107  \n",
      "1 -15.186732 -7.869560 -19.856249   0.905157  14.031210  -7.943602   0.409077  \n",
      "2 -32.729615 -6.824061 -24.733979   9.816871  17.845332 -10.393979   1.222533  \n",
      "3 -44.176893  2.572497  -9.289730  18.219619  -2.507135 -10.255756 -11.767249  \n",
      "4 -33.785017  0.292941  -7.614792  11.982033 -27.634276  -8.691069 -19.353915  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define the directory containing the Parquet files\n",
    "parquet_directory = '/home/owner/Documents/DEV/BrainLabyrinth/data/final_dataset (copy)'\n",
    "\n",
    "# List all Parquet files in the directory\n",
    "parquet_files = [os.path.join(parquet_directory, f) for f in os.listdir(parquet_directory) if f.endswith('.parquet')]\n",
    "\n",
    "# Initialize an empty list to hold the Dask DataFrames\n",
    "dask_dfs = []\n",
    "\n",
    "# Process each Parquet file\n",
    "for file in parquet_files:\n",
    "    # Read the Parquet file into a Dask DataFrame\n",
    "    df = dd.read_parquet(file)\n",
    "\n",
    "    # Extract the file name without the extension\n",
    "    file_name = os.path.basename(file).replace('.parquet', '')\n",
    "\n",
    "    # Create a unique event_id by combining the original event_id with the file name\n",
    "    df['event_id'] = df['event_id'].astype(str) + '_' + file_name\n",
    "\n",
    "    # Append the DataFrame to the list\n",
    "    dask_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single Dask DataFrame\n",
    "combined_df = dd.concat(dask_dfs, ignore_index=True)\n",
    "\n",
    "# Create a mapping dictionary for unique event_id values\n",
    "unique_event_ids = combined_df['event_id'].unique().compute()\n",
    "event_id_mapping = {event_id: idx for idx, event_id in enumerate(unique_event_ids)}\n",
    "\n",
    "# Renumber the event_id column using the mapping dictionary\n",
    "combined_df['event_id'] = combined_df['event_id'].map(event_id_mapping, meta=('event_id', 'int64'))\n",
    "\n",
    "# Optionally, you can perform operations on the combined Dask DataFrame\n",
    "# For example, you can compute the first few rows to verify the data\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save the combined Dask DataFrame to a new Parquet file\n",
    "combined_df.to_parquet('/home/owner/Documents/DEV/BrainLabyrinth/data/combined.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owner/Documents/DEV/BrainLabyrinth/.venv/lib/python3.10/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final dataset: (1263656, 67)\n",
      "   event_id      marker    time        Fp1        Fpz        Fp2         F7  \\\n",
      "0         0  Stimulus/P  23.620  18.929390  27.035186  26.474021 -37.195889   \n",
      "1         0  Stimulus/P  23.622  21.587595  26.084012  25.872122 -34.220734   \n",
      "2         0  Stimulus/P  23.624  22.985251  22.778513  20.055913 -32.408453   \n",
      "3         0  Stimulus/P  23.626  26.445074  26.938968  21.746364 -29.977234   \n",
      "4         0  Stimulus/P  23.628  27.858514  33.056260  30.219951 -27.094996   \n",
      "\n",
      "         F3         Fz         F4  ...        PO3        PO4       PO6  \\\n",
      "0  8.102022  26.115237  13.509483  ... -13.759602  -6.662856 -7.093113   \n",
      "1  2.335635  25.532525  17.738738  ... -15.645522  -9.955678 -9.481412   \n",
      "2  1.843952  23.887538  14.971009  ...  -7.170127 -12.647842 -9.841793   \n",
      "3  6.261537  25.611078  17.984585  ... -13.886536 -11.800133 -9.656715   \n",
      "4  9.726444  30.116939  19.419637  ... -27.232310 -10.963815 -8.354059   \n",
      "\n",
      "         FT7       FT8        TP7        TP8        PO7        PO8         Oz  \n",
      "0 -14.274561 -5.782883 -20.014128  11.247635   5.061285  -6.010722 -10.334107  \n",
      "1 -15.186732 -7.869560 -19.856249   0.905157  14.031210  -7.943602   0.409077  \n",
      "2 -32.729615 -6.824061 -24.733979   9.816871  17.845332 -10.393979   1.222533  \n",
      "3 -44.176893  2.572497  -9.289730  18.219619  -2.507135 -10.255756 -11.767249  \n",
      "4 -33.785017  0.292941  -7.614792  11.982033 -27.634276  -8.691069 -19.353915  \n",
      "\n",
      "[5 rows x 67 columns]\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Define the directory containing the Parquet files\n",
    "parquet_directory = '/home/owner/Documents/DEV/BrainLabyrinth/data/combined.parquet'\n",
    "\n",
    "# Read the Parquet files into a Dask DataFrame\n",
    "dask_df = dd.read_parquet(parquet_directory)\n",
    "\n",
    "# Compute the shape of the Dask DataFrame\n",
    "rows, cols = dask_df.shape\n",
    "rows_computed = rows.compute()\n",
    "\n",
    "# Print the shape\n",
    "print(f\"Shape of the final dataset: ({rows_computed}, {cols})\")\n",
    "\n",
    "# Optionally, you can compute the first few rows to verify the data\n",
    "print(dask_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
