{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Must be first!\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    ReduceLROnPlateau,\n",
    "    LambdaLR\n",
    ")\n",
    "\n",
    "import polars as pl\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "###################\n",
    "from model import EEGMobileNet\n",
    "from dataset import EEGDatasetV2\n",
    "from utils import collate_fn\n",
    "###################\n",
    "\n",
    "# Set seeds and deterministic flags\n",
    "\n",
    "torch.use_deterministic_algorithms(True)  # Enable full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_id',\n",
       " 'orig_marker',\n",
       " 'time',\n",
       " 'Fp1',\n",
       " 'Fpz',\n",
       " 'Fp2',\n",
       " 'F7',\n",
       " 'F3',\n",
       " 'Fz',\n",
       " 'F4',\n",
       " 'F8',\n",
       " 'FC5',\n",
       " 'FC1',\n",
       " 'FC2',\n",
       " 'FC6',\n",
       " 'M1',\n",
       " 'T7',\n",
       " 'C3',\n",
       " 'Cz',\n",
       " 'C4',\n",
       " 'T8',\n",
       " 'M2',\n",
       " 'CP5',\n",
       " 'CP1',\n",
       " 'CP2',\n",
       " 'CP6',\n",
       " 'P7',\n",
       " 'P3',\n",
       " 'Pz',\n",
       " 'P4',\n",
       " 'P8',\n",
       " 'POz',\n",
       " 'O1',\n",
       " 'O2',\n",
       " 'AF7',\n",
       " 'AF3',\n",
       " 'AF4',\n",
       " 'AF8',\n",
       " 'F5',\n",
       " 'F1',\n",
       " 'F2',\n",
       " 'F6',\n",
       " 'FC3',\n",
       " 'FCz',\n",
       " 'FC4',\n",
       " 'C5',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C6',\n",
       " 'CP3',\n",
       " 'CP4',\n",
       " 'P5',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'P6',\n",
       " 'PO5',\n",
       " 'PO3',\n",
       " 'PO4',\n",
       " 'PO6',\n",
       " 'FT7',\n",
       " 'FT8',\n",
       " 'TP7',\n",
       " 'TP8',\n",
       " 'PO7',\n",
       " 'PO8',\n",
       " 'Oz',\n",
       " 'marker',\n",
       " 'prev_marker']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('/home/owner/Documents/DEV/BrainLabyrinth/data/combined_prev_prev.parquet')\\\n",
    "    .columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_set, train_loader, val_loader):\n",
    "    # -------------------- MODEL --------------------\n",
    "    model = EEGMobileNet(\n",
    "        in_channels=65,\n",
    "        num_classes=1,\n",
    "        dropout=config['dropout']\n",
    "    ).to(config['device'])\n",
    "    \n",
    "    # ------------------ LOSS FUNCTION ------------------\n",
    "    pos_weight = torch.tensor([\n",
    "        train_set.class_weights['Left'] / train_set.class_weights['Right']\n",
    "    ]).to(config['device'])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight=pos_weight)\n",
    "    \n",
    "    # ------------------- OPTIMIZER ---------------------\n",
    "    lr = config.get('lr', 1e-3)\n",
    "    weight_decay = config.get('weight_decay', 1e-2)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # ------------------- SCHEDULER ---------------------\n",
    "    scheduler_config = config.get('scheduler', {})\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=scheduler_config.get('mode', 'min'),\n",
    "        factor=scheduler_config.get('factor', 0.1),\n",
    "        patience=scheduler_config.get('patience', 10),\n",
    "        threshold=scheduler_config.get('threshold', 0.0001),\n",
    "        cooldown=scheduler_config.get('cooldown', 0),\n",
    "        min_lr=scheduler_config.get('min_lr', 0),\n",
    "    )\n",
    "    \n",
    "    # ------------------- WARMUP SCHEDULER ---------------\n",
    "    warmup_epochs = config.get('warmup_epochs', 0)\n",
    "    if warmup_epochs > 0:\n",
    "        warmup_scheduler = LambdaLR(\n",
    "            optimizer,\n",
    "            lambda epoch: min(1.0, (epoch + 1) / warmup_epochs)\n",
    "        )\n",
    "    else:\n",
    "        warmup_scheduler = None\n",
    "    \n",
    "    # -------------------- TRAINING LOOP --------------------\n",
    "    best_metric = -float(\"inf\")\n",
    "    best_model_weights = None  # will hold a copy of state_dict()\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # ---------- TRAIN ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for labels, features in train_loader:\n",
    "            features = features.to(config['device']).float()\n",
    "            labels = labels.to(config['device']).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (if specified)\n",
    "            if config.get('grad_clip') is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # ---------- VALIDATION ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for labels, features in val_loader:\n",
    "                features = features.to(config['device']).float()\n",
    "                labels = labels.to(config['device']).float()\n",
    "                \n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        predictions = (np.array(all_preds) > 0.5).astype(int)\n",
    "        \n",
    "        # ---------- METRICS ----------\n",
    "        accuracy = accuracy_score(all_labels, predictions)\n",
    "        \n",
    "        # ---------- SCHEDULER UPDATE ----------        \n",
    "        if warmup_scheduler is not None and epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "        \n",
    "\n",
    "        \n",
    "        # ---------- SAVE BEST MODEL ----------\n",
    "        if accuracy > best_metric:\n",
    "            best_metric = accuracy\n",
    "            best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # After the loop, restore the best weights\n",
    "    best_model = EEGMobileNet(\n",
    "        in_channels=65,\n",
    "        num_classes=1,\n",
    "        dropout=config['dropout']\n",
    "    ).to(config['device'])\n",
    "\n",
    "    best_model.load_state_dict(best_model_weights)\n",
    "\n",
    "    # Now best_model is truly the best epochâ€™s model\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_data = {\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "train_set = torch.load('train_set.pt', weights_only=False)\n",
    "val_set = torch.load('val_set.pt', weights_only=False)\n",
    "test_set = torch.load('test_set.pt', weights_only=False)\n",
    "\n",
    "generator = torch.Generator().manual_seed(69)  # Set seed\n",
    "initial_state = generator.get_state()\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config_data['batch_size'],\n",
    "    shuffle=True,\n",
    "    generator=generator,  # Add this line\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(val_set, batch_size=config_data['batch_size'], collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=config_data['batch_size'], collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_adamw_plateau(trial, generator, initial_state, train_set, train_loader, val_loader, device):\n",
    "    random.seed(69)\n",
    "    np.random.seed(69)\n",
    "    torch.manual_seed(69)\n",
    "    torch.cuda.manual_seed(69)\n",
    "    generator.set_state(initial_state)\n",
    "\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5)\n",
    "    \n",
    "    # Scheduler params\n",
    "    factor = trial.suggest_float(\"factor\", 0.1, 0.8)\n",
    "    patience = trial.suggest_int(\"patience\", 2, 25)\n",
    "    cooldown = trial.suggest_int(\"cooldown\", 10, 25)\n",
    "    \n",
    "    config = {\n",
    "        \"device\": device,\n",
    "        \"dropout\": dropout,\n",
    "        \"epochs\": 300,\n",
    "        \"log_dir\": \"./runs/OptunaTest\",\n",
    "        \"warmup_epochs\": 0,\n",
    "        \"grad_clip\": None,\n",
    "        \"lr\": lr,\n",
    "        \"weight_decay\": weight_decay,\n",
    "        \n",
    "        # Scheduler config\n",
    "        \"scheduler\": {\n",
    "            \"mode\": \"min\",\n",
    "            \"factor\": factor,\n",
    "            \"patience\": patience,\n",
    "            \"threshold\": 0.0001,\n",
    "            \"cooldown\": cooldown,\n",
    "            \"min_lr\": 1e-8,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    best_model = train_model(config, train_set, train_loader, val_loader)\n",
    "\n",
    "    # Move model to the correct device\n",
    "    best_model = best_model.to(config['device'])\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    best_model.eval()\n",
    "\n",
    "    all_test_markers = []\n",
    "    all_test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for markers, features in test_loader:\n",
    "            features = features.to(config['device'])\n",
    "            markers = markers.to(config['device'])\n",
    "\n",
    "            outputs = best_model(features)\n",
    "            # Collect markers and predictions for metrics calculation\n",
    "            all_test_markers.extend(markers.cpu().numpy().flatten())\n",
    "            all_test_predictions.extend(torch.sigmoid(outputs).cpu().numpy().flatten())\n",
    "\n",
    "    test_accuracy = accuracy_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "    \n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "272e98e276844d978e0521525beb857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial: 0.678743961352657\n",
      "Best Hyperparams: {'lr': 7.874218712024844e-05, 'weight_decay': 6.044655803896766e-06, 'dropout': 0.4991027500704538, 'factor': 0.127815027666582, 'patience': 18, 'cooldown': 12}\n"
     ]
    }
   ],
   "source": [
    "# Example: Tuning AdamW + CyclicLR\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    lambda trial: objective_adamw_plateau(\n",
    "        trial, generator, initial_state, train_set, train_loader, val_loader, device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    ),\n",
    "    n_trials=500,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "print(\"Best Trial:\", study.best_trial.value)\n",
    "print(\"Best Hyperparams:\", study.best_trial.params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from datetime import datetime\n",
    "with open(f'study_{datetime.now().isoformat()}.pkl', 'wb') as f:\n",
    "    pickle.dump(study.best_trial.params, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 0.0004289043733964325,\n",
       " 'weight_decay': 7.005604917505383e-06,\n",
       " 'dropout': 0.29873479051843843,\n",
       " 'factor': 0.3733438612483646,\n",
       " 'patience': 22,\n",
       " 'cooldown': 13}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
