{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Must be first!\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    ReduceLROnPlateau,\n",
    "    LambdaLR,\n",
    "    CosineAnnealingWarmRestarts\n",
    ")\n",
    "\n",
    "from transformers import AdamW, get_cosine_schedule_with_warmup\n",
    "\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "###################\n",
    "from utils import collate_fn\n",
    "###################\n",
    "\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import EEGPTDataset  # Your existing dataset class\n",
    "from model import EEGPTWrapper\n",
    "\n",
    "# Set seeds and deterministic flags\n",
    "random.seed(69)\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "torch.cuda.manual_seed(69)\n",
    "torch.use_deterministic_algorithms(True)  # Enable full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = pd.read_parquet('/home/owner/Documents/DEV/BrainLabyrinth/data/combined_GPT.parquet').columns.str.upper()\n",
    "required = pd.Series([\n",
    "    'FP1', 'FPZ', 'FP2', 'AF3', 'AF4', \n",
    "    'F7', 'F5', 'F3', 'F1', 'FZ', \n",
    "    'F2', 'F4', 'F6', 'F8', 'FT7', \n",
    "    'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', \n",
    "    'FC4', 'FC6', 'FT8', 'T7', 'C5', \n",
    "    'C3', 'C1', 'CZ', 'C2', 'C4', \n",
    "    'C6', 'T8', 'TP7', 'CP5', 'CP3', \n",
    "    'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', \n",
    "    'TP8', 'P7', 'P5', 'P3', 'P1', \n",
    "    'PZ', 'P2', 'P4', 'P6', 'P8', \n",
    "    'PO7', 'PO3', 'POZ',  'PO4', 'PO8', \n",
    "    'O1', 'OZ', 'O2' \n",
    "])\n",
    "\n",
    "print(required[~required.isin(columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_set, train_loader, val_loader, writer):\n",
    "    # -------------------- MODEL --------------------\n",
    "    model = EEGPTWrapper(\n",
    "        pretrained_path=\"checkpoint/eegpt_mcae_58chs_4s_large4E.ckpt\",\n",
    "        channel_list=[\n",
    "            'FP1', 'FPZ', 'FP2', 'AF3', 'AF4', \n",
    "            'F7', 'F5', 'F3', 'F1', 'FZ', \n",
    "            'F2', 'F4', 'F6', 'F8', 'FT7', \n",
    "            'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', \n",
    "            'FC4', 'FC6', 'FT8', 'T7', 'C5', \n",
    "            'C3', 'C1', 'CZ', 'C2', 'C4', \n",
    "            'C6', 'T8', 'TP7', 'CP5', 'CP3', \n",
    "            'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', \n",
    "            'TP8', 'P7', 'P5', 'P3', 'P1', \n",
    "            'PZ', 'P2', 'P4', 'P6', 'P8', \n",
    "            'PO7', 'PO3', 'POZ',  'PO4', 'PO8', \n",
    "            'O1', 'OZ', 'O2' \n",
    "        ],\n",
    "        num_classes=1\n",
    "    ).to(config['device'])\n",
    "\n",
    "    \n",
    "    # Log model architecture and config\n",
    "    writer.add_text(\"Model/Structure\", str(model))\n",
    "    writer.add_text(\"Training Config\", str(config))\n",
    "    \n",
    "    # ------------------ LOSS FUNCTION ------------------\n",
    "    pos_weight = torch.tensor([\n",
    "        train_set.class_weights['Left'] / train_set.class_weights['Right']\n",
    "    ]).to(config['device'])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight=pos_weight)\n",
    "    \n",
    "    # ------------------- OPTIMIZER ---------------------\n",
    "    lr = config.get('lr', 1e-3)\n",
    "    weight_decay = config.get('weight_decay', 1e-2)    \n",
    "\n",
    "    optimizer = AdamW(model.eegpt.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # ------------------- SCHEDULER ---------------------\n",
    "    \n",
    "    total_steps = config['epochs'] * len(train_loader)\n",
    "    warmup_epochs = config.get('warmup_epochs', 0)\n",
    "    num_cycles = config.get('num_cycles', 0.5)\n",
    "    scheduler = get_cosine_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=warmup_epochs, num_training_steps=total_steps, num_cycles=num_cycles\n",
    "    )\n",
    "    \n",
    "    # # ------------------- WARMUP SCHEDULER ---------------\n",
    "    # warmup_epochs = config.get('warmup_epochs', 0)\n",
    "    # if warmup_epochs > 0:\n",
    "    #     warmup_scheduler = LambdaLR(\n",
    "    #         optimizer,\n",
    "    #         lambda epoch: min(1.0, (epoch + 1) / warmup_epochs)\n",
    "    #     )\n",
    "    # else:\n",
    "    #     warmup_scheduler = None\n",
    "    \n",
    "    # -------------------- TRAINING LOOP --------------------\n",
    "    best_metric = -float('inf')\n",
    "    \n",
    "    for epoch in tqdm(range(config['epochs']), desc=\"Training\"):\n",
    "        # ---------- TRAIN ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for labels, features in train_loader:\n",
    "            features = features.to(config['device']).float()\n",
    "            labels = labels.to(config['device']).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (if specified)\n",
    "            if config.get('grad_clip') is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # ---------- VALIDATION ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for labels, features in val_loader:\n",
    "                features = features.to(config['device']).float()\n",
    "                labels = labels.to(config['device']).float()\n",
    "                \n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        predictions = (np.array(all_preds) > 0.5).astype(int)\n",
    "        \n",
    "        # ---------- METRICS ----------\n",
    "        accuracy = accuracy_score(all_labels, predictions)\n",
    "        precision = precision_score(all_labels, predictions)\n",
    "        recall = recall_score(all_labels, predictions)\n",
    "        f1 = f1_score(all_labels, predictions)\n",
    "        \n",
    "        # ---------- SCHEDULER UPDATE ----------\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # if warmup_scheduler is not None and epoch < warmup_epochs:\n",
    "        #     warmup_scheduler.step()\n",
    "        # else:\n",
    "        #     if scheduler is not None:\n",
    "        #         scheduler.step(val_loss)\n",
    "        \n",
    "        # ---------- LOGGING ----------\n",
    "        writer.add_scalar('LR', current_lr, epoch)\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        writer.add_scalar('F1', f1, epoch)\n",
    "        \n",
    "        # You can also combine them in a single dictionary\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "        writer.add_scalars('Metrics', metrics, epoch)\n",
    "        \n",
    "        # ---------- SAVE BEST MODEL ----------\n",
    "        if accuracy > best_metric:\n",
    "            best_metric = accuracy\n",
    "            torch.save(model.state_dict(), f\"{config['log_dir']}/best_model.pth\")\n",
    "    \n",
    "    writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_study = {\n",
    "    'lr': 3e-4,\n",
    "    'weight_decay': 0, #2.215232012031863e-05,\n",
    " }\n",
    "\n",
    "config = {\n",
    "    'data_path': '/home/owner/Documents/DEV/BrainLabyrinth/data/combined_GPT.parquet',\n",
    "    'pretrained_path': 'checkpoint/eegpt_mcae_58chs_4s_large4E.ckpt',\n",
    "    'split_ratios': (0.7, 0.15, 0.15),\n",
    "    'batch_size': 64,\n",
    "    'epochs': 600,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_dir': './runs/EEGPT',\n",
    "    'lr': config_study['lr'],\n",
    "    'weight_decay': config_study['weight_decay'],\n",
    "    'grad_clip': 5,\n",
    "    'warmup_epochs': 100,\n",
    "    'num_cycles': 1.5,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating full dataset...\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f451fa0eca47a29cc9d48b86c33eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing Samples:   0%|          | 0/2772 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "Splitting the dataset...\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53557965c3e84bda9f5eb8723cf33b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing Samples:   0%|          | 0/1940 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1ace24ad8a4fc8b5d545cd5970071c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing Samples:   0%|          | 0/415 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "Precomputing samples...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3717ec08e2494697117a5739ebca77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Precomputing Samples:   0%|          | 0/417 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing class weights...\n",
      "unbalanced train dataset shape: (1940, [labels: torch.Size([]), features: [1024, 58]])\n"
     ]
    }
   ],
   "source": [
    "#============================================================\n",
    "# Training Pipeline\n",
    "#============================================================\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Initialize dataset\n",
    "print(\"Creating full dataset...\")\n",
    "full_dataset = EEGPTDataset(config['data_path'], max_length=1024)\n",
    "\n",
    "print(\"Splitting the dataset...\")\n",
    "# Split dataset\n",
    "train_set, val_set, test_set = full_dataset.split_dataset(\n",
    "    ratios=config['split_ratios']\n",
    ")\n",
    "\n",
    "del full_dataset\n",
    "\n",
    "len_dataset = len(train_set)\n",
    "sample = train_set[0]\n",
    "label_shape = sample[0].shape\n",
    "feature_shape = sample[1].shape\n",
    "\n",
    "print(f\"unbalanced train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "torch.save(train_set, 'train_set_smol_GPT.pt')\n",
    "torch.save(val_set, 'val_set_GPT.pt')\n",
    "torch.save(test_set, 'test_set_GPT.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (1940, [labels: torch.Size([]), features: [1024, 58]])\n"
     ]
    }
   ],
   "source": [
    "train_set = torch.load('train_set_smol_GPT.pt', weights_only=False)\n",
    "val_set = torch.load('val_set_GPT.pt', weights_only=False)\n",
    "test_set = torch.load('test_set_GPT.pt', weights_only=False)\n",
    "\n",
    "\n",
    "generator = torch.Generator().manual_seed(69)  # Set seed\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    generator=generator,  # Add this line\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    # collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(val_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "\n",
    "len_dataset = len(train_set)\n",
    "sample = train_set[0]\n",
    "label_shape = sample[0].shape\n",
    "feature_shape = sample[1].shape\n",
    "\n",
    "print(f\"train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "writer = SummaryWriter(log_dir=config['log_dir'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923db703f90f4d89a88f2a0614a44907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/600 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "trained_model = train_model(config, train_set, train_loader, val_loader, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnotebook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\u001b[0;32m----> 5\u001b[0m best_model \u001b[38;5;241m=\u001b[39m \u001b[43mEEGPTWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mruns/EEGPT/best_model.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#\"checkpoint/eegpt_mcae_58chs_4s_large4E.ckpt\",\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchannel_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFP2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFPZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFP1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAF4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAF3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mF8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFT7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFCZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFC4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFT8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mT8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTP7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCPZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCP4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTP8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP6\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mP8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPO7\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPO3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mO2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPO4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPO8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOZ\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Adjust parameters as needed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Load the state dictionary\u001b[39;00m\n\u001b[1;32m     19\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_dir\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/best_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/DEV/BrainLabyrinth/model.py:72\u001b[0m, in \u001b[0;36mEEGPTWrapper.__init__\u001b[0;34m(self, pretrained_path, channel_list, num_classes)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# 1) Load the weights\u001b[39;00m\n\u001b[1;32m     66\u001b[0m ckpt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m     67\u001b[0m     pretrained_path,\n\u001b[1;32m     68\u001b[0m     map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     69\u001b[0m     weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# <--- override the default True in PyTorch 2.6\u001b[39;00m\n\u001b[1;32m     70\u001b[0m )\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meegpt\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mckpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# 2). Freeze everything if you want\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meegpt\u001b[38;5;241m.\u001b[39mparameters():\n",
      "\u001b[0;31mKeyError\u001b[0m: 'state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "best_model = EEGPTWrapper(\n",
    "    pretrained_path=\"checkpoint/eegpt_mcae_58chs_4s_large4E.ckpt\",\n",
    "    channel_list=[\n",
    "            \"FP2\", \"FPZ\", \"FP1\", \"AF4\", \"AF3\", \"F7\", \"F5\", \"F3\", \"F6\", \"F1\",\n",
    "            \"FZ\", \"F2\", \"F4\", \"F8\", \"FT7\", \"FC5\", \"FC3\", \"FC6\", \"FC1\", \"FCZ\",\n",
    "            \"FC2\", \"FC4\", \"FT8\", \"T7\", \"C5\", \"C3\", \"C6\", \"C1\", \"CZ\", \"C2\",\n",
    "            \"C4\", \"T8\", \"TP7\", \"CP5\", \"CP3\", \"CP6\", \"CP1\", \"CPZ\", \"CP2\", \"CP4\",\n",
    "            \"TP8\", \"P7\", \"P5\", \"P3\", \"P6\", \"P1\", \"PZ\", \"P2\", \"P4\", \"P8\",\n",
    "            \"O1\", \"PO7\", \"PO3\", \"O2\", \"OZ\", \"PO4\", \"PO8\", \"POZ\"\n",
    "        ],\n",
    "    num_classes=1\n",
    ")  # Adjust parameters as needed\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(f\"{config['log_dir']}/best_model.pth\", map_location=config['device'])\n",
    "best_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move model to the correct device\n",
    "best_model = best_model.to(config['device'])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "best_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "all_test_markers = []\n",
    "all_test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for markers, features in tqdm(test_loader):\n",
    "        features = features.to(config['device'])\n",
    "        markers = markers.to(config['device'])\n",
    "\n",
    "        outputs = best_model(features)\n",
    "\n",
    "        # Collect markers and predictions for metrics calculation\n",
    "        all_test_markers.extend(markers.cpu().numpy().flatten())\n",
    "        all_test_predictions.extend(torch.sigmoid(outputs).cpu().numpy().flatten())\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_precision = precision_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_recall = recall_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_f1 = f1_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_roc_auc = roc_auc_score(all_test_markers, all_test_predictions)\n",
    "\n",
    "# Log test metrics to TensorBoard\n",
    "writer.add_scalar('Metrics/test_accuracy', test_accuracy, 1)\n",
    "writer.add_scalar('Metrics/test_precision', test_precision, 1)\n",
    "writer.add_scalar('Metrics/test_recall', test_recall, 1)\n",
    "writer.add_scalar('Metrics/test_f1', test_f1, 1)\n",
    "writer.add_scalar('Metrics/test_roc_auc', test_roc_auc, 1)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_accuracy=0.4844124700239808\n",
      "test_precision=0.4823529411764706\n",
      "test_recall=0.8078817733990148\n",
      "test_f1=0.6040515653775322\n",
      "test_roc_auc=np.float64(0.4886400257815018)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{test_accuracy=}\n",
    "{test_precision=}\n",
    "{test_recall=}\n",
    "{test_f1=}\n",
    "{test_roc_auc=}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a11e4da349b44988d8eed07295af0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.1)\n",
      "best_f1=0.6548387096774193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_accuracy = f1_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_accuracy > best_f1:\n",
    "        best_f1 = current_accuracy\n",
    "        best_threshold = threshold\n",
    "        test_accuracy = accuracy_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"{best_f1=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf0bf4c2d4e45558b9420ec9edfb865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.53)\n",
      "best_accuracy=0.5251798561151079\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "best_threshold = 0.1\n",
    "best_accuracy = 0.0\n",
    "thresholds = np.arange(0.005, 1.0, 0.005)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_accuracy = accuracy_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"{best_accuracy=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42953d9d152c476da0731f9e9806f377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.53)\n",
      "\n",
      "      best_accuracy=0.5251798561151079\n",
      "    precision=0.4823529411764706\n",
      "    recall=0.8078817733990148\n",
      "    f1=0.6040515653775322\n",
      "    roc_auc=np.float64(0.4886400257815018)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "best_threshold = 0.1\n",
    "best_accuracy = 0.0\n",
    "thresholds = np.arange(0.005, 1.0, 0.005)\n",
    "\n",
    "\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_accuracy = accuracy_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_accuracy > best_accuracy:\n",
    "        best_accuracy = current_accuracy\n",
    "        best_threshold = threshold\n",
    "        precision = precision_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "        recall = recall_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "        f1 = f1_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "        roc_auc = roc_auc_score(all_test_markers, all_test_predictions)\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"\"\"\n",
    "      {best_accuracy=}\n",
    "    {precision=}\n",
    "    {recall=}\n",
    "    {f1=}\n",
    "    {roc_auc=}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
