{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Must be first!\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from torch.nn.utils.rnn import pad_sequence\n",
    "# import torch.nn.functional as F\n",
    "# from torch.optim.lr_scheduler import (\n",
    "#     ReduceLROnPlateau,\n",
    "#     CosineAnnealingLR,\n",
    "#     CyclicLR,\n",
    "#     OneCycleLR,\n",
    "#     LambdaLR\n",
    "# )\n",
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# import polars as pl\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from tqdm.notebook import tqdm\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# import random\n",
    "# import numpy as np\n",
    "\n",
    "# from scipy.interpolate import CubicSpline\n",
    "\n",
    "# # Set seeds and deterministic flags\n",
    "# random.seed(69)\n",
    "# np.random.seed(69)\n",
    "# torch.manual_seed(69)\n",
    "# torch.cuda.manual_seed(69)\n",
    "# torch.use_deterministic_algorithms(True)  # Enable full determinism\n",
    "# torch.backends.cudnn.deterministic = True\n",
    "# torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Must be first!\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    ReduceLROnPlateau,\n",
    "    LambdaLR\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import polars as pl\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import optuna\n",
    "\n",
    "###################\n",
    "from model import EEGMobileNet\n",
    "from dataset import EEGDataset\n",
    "from utils import collate_fn\n",
    "###################\n",
    "\n",
    "# Set seeds and deterministic flags\n",
    "random.seed(69)\n",
    "np.random.seed(69)\n",
    "torch.manual_seed(69)\n",
    "torch.cuda.manual_seed(69)\n",
    "torch.use_deterministic_algorithms(True)  # Enable full determinism\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['event_id',\n",
       " 'orig_marker',\n",
       " 'time',\n",
       " 'Fp1',\n",
       " 'Fpz',\n",
       " 'Fp2',\n",
       " 'F7',\n",
       " 'F3',\n",
       " 'Fz',\n",
       " 'F4',\n",
       " 'F8',\n",
       " 'FC5',\n",
       " 'FC1',\n",
       " 'FC2',\n",
       " 'FC6',\n",
       " 'M1',\n",
       " 'T7',\n",
       " 'C3',\n",
       " 'Cz',\n",
       " 'C4',\n",
       " 'T8',\n",
       " 'M2',\n",
       " 'CP5',\n",
       " 'CP1',\n",
       " 'CP2',\n",
       " 'CP6',\n",
       " 'P7',\n",
       " 'P3',\n",
       " 'Pz',\n",
       " 'P4',\n",
       " 'P8',\n",
       " 'POz',\n",
       " 'O1',\n",
       " 'O2',\n",
       " 'AF7',\n",
       " 'AF3',\n",
       " 'AF4',\n",
       " 'AF8',\n",
       " 'F5',\n",
       " 'F1',\n",
       " 'F2',\n",
       " 'F6',\n",
       " 'FC3',\n",
       " 'FCz',\n",
       " 'FC4',\n",
       " 'C5',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C6',\n",
       " 'CP3',\n",
       " 'CP4',\n",
       " 'P5',\n",
       " 'P1',\n",
       " 'P2',\n",
       " 'P6',\n",
       " 'PO5',\n",
       " 'PO3',\n",
       " 'PO4',\n",
       " 'PO6',\n",
       " 'FT7',\n",
       " 'FT8',\n",
       " 'TP7',\n",
       " 'TP8',\n",
       " 'PO7',\n",
       " 'PO8',\n",
       " 'Oz',\n",
       " 'marker',\n",
       " 'prev_marker']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.read_parquet('/home/owner/Documents/DEV/BrainLabyrinth/data/combined.parquet')\\\n",
    "    .columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config, train_set, train_loader, val_loader, writer):\n",
    "    # -------------------- MODEL --------------------\n",
    "    model = EEGMobileNet(\n",
    "        in_channels=64,\n",
    "        num_classes=1,\n",
    "        dropout=config['dropout']\n",
    "    ).to(config['device'])\n",
    "        \n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.BatchNorm1d):\n",
    "            assert not layer.track_running_stats, \\\n",
    "                f\"BatchNorm layer {name} should have track_running_stats=False\"\n",
    "    \n",
    "    # Log model architecture and config\n",
    "    writer.add_text(\"Model/Type\", f\"EEGMobileNet with dropout={config['dropout']}\")\n",
    "    writer.add_text(\"Model/Structure\", str(model))\n",
    "    writer.add_text(\"Training Config\", str(config))\n",
    "    \n",
    "    # ------------------ LOSS FUNCTION ------------------\n",
    "    pos_weight = torch.tensor([\n",
    "        train_set.class_weights['Left'] / train_set.class_weights['Right']\n",
    "    ]).to(config['device'])\n",
    "    criterion = torch.nn.BCEWithLogitsLoss(weight=pos_weight)\n",
    "    \n",
    "    # ------------------- OPTIMIZER ---------------------\n",
    "    lr = config.get('lr', 1e-3)\n",
    "    weight_decay = config.get('weight_decay', 1e-2)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    # ------------------- SCHEDULER ---------------------\n",
    "    scheduler_config = config.get('scheduler', {})\n",
    "    \n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode=scheduler_config.get('mode', 'min'),\n",
    "        factor=scheduler_config.get('factor', 0.1),\n",
    "        patience=scheduler_config.get('patience', 10),\n",
    "        threshold=scheduler_config.get('threshold', 0.0001),\n",
    "        cooldown=scheduler_config.get('cooldown', 0),\n",
    "        min_lr=scheduler_config.get('min_lr', 0),\n",
    "    )\n",
    "    \n",
    "    # ------------------- WARMUP SCHEDULER ---------------\n",
    "    warmup_epochs = config.get('warmup_epochs', 0)\n",
    "    if warmup_epochs > 0:\n",
    "        warmup_scheduler = LambdaLR(\n",
    "            optimizer,\n",
    "            lambda epoch: min(1.0, (epoch + 1) / warmup_epochs)\n",
    "        )\n",
    "    else:\n",
    "        warmup_scheduler = None\n",
    "    \n",
    "    # -------------------- TRAINING LOOP --------------------\n",
    "    best_metric = -float('inf')\n",
    "    \n",
    "    for epoch in tqdm(range(config['epochs']), desc=\"Training\"):\n",
    "        # ---------- TRAIN ----------\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for labels, features in train_loader:\n",
    "            features = features.to(config['device']).float()\n",
    "            labels = labels.to(config['device']).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping (if specified)\n",
    "            if config.get('grad_clip') is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), config['grad_clip'])\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        # ---------- VALIDATION ----------\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for labels, features in val_loader:\n",
    "                features = features.to(config['device']).float()\n",
    "                labels = labels.to(config['device']).float()\n",
    "                \n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                preds = torch.sigmoid(outputs)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        predictions = (np.array(all_preds) > 0.5).astype(int)\n",
    "        \n",
    "        # ---------- METRICS ----------\n",
    "        accuracy = accuracy_score(all_labels, predictions)\n",
    "        precision = precision_score(all_labels, predictions)\n",
    "        recall = recall_score(all_labels, predictions)\n",
    "        f1 = f1_score(all_labels, predictions)\n",
    "        \n",
    "        # ---------- SCHEDULER UPDATE ----------\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        if warmup_scheduler is not None and epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            if scheduler is not None:\n",
    "                scheduler.step(val_loss)\n",
    "        \n",
    "        # ---------- LOGGING ----------\n",
    "        writer.add_scalar('LR', current_lr, epoch)\n",
    "        writer.add_scalar('Loss/Train', train_loss, epoch)\n",
    "        writer.add_scalar('Loss/Val', val_loss, epoch)\n",
    "        writer.add_scalar('Accuracy', accuracy, epoch)\n",
    "        writer.add_scalar('Precision', precision, epoch)\n",
    "        writer.add_scalar('Recall', recall, epoch)\n",
    "        writer.add_scalar('F1', f1, epoch)\n",
    "        \n",
    "        # You can also combine them in a single dictionary\n",
    "        metrics = {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        }\n",
    "        writer.add_scalars('Metrics', metrics, epoch)\n",
    "        \n",
    "        # ---------- SAVE BEST MODEL ----------\n",
    "        if accuracy > best_metric:\n",
    "            best_metric = accuracy\n",
    "            torch.save(model.state_dict(), f\"{config['log_dir']}/best_model.pth\")\n",
    "    \n",
    "    writer.close()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lr': 9.765820104617875e-05,\n",
       " 'weight_decay': 1.8290404005473213e-05,\n",
       " 'dropout': 0.35994387648460596,\n",
       " 'factor': 0.19990106143116088,\n",
       " 'patience': 7,\n",
       " 'cooldown': 16}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('study.pkl', 'rb') as f:\n",
    "    config_study = pickle.load(f)\n",
    "    \n",
    "required_keys = ['lr', 'weight_decay', 'dropout', 'factor', 'patience', 'cooldown']\n",
    "assert all(k in config_study for k in required_keys), \\\n",
    "    f\"Missing Optuna parameters: {set(required_keys) - set(config_study.keys())}\"\n",
    "    \n",
    "config_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'data_path': '/home/owner/Documents/DEV/BrainLabyrinth/data/combined.parquet',\n",
    "    'split_ratios': (0.7, 0.15, 0.15),\n",
    "    'batch_size': 32,\n",
    "    'dropout': config_study['dropout'],\n",
    "    'epochs': 300,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_dir': './runs/CNN',\n",
    "\n",
    "    # <<< Global LR and Weight Decay here >>>\n",
    "    'lr': config_study['lr'],\n",
    "    'weight_decay': config_study['weight_decay'],\n",
    "    'factor': config_study['factor'],\n",
    "    'patience': config_study['patience'],\n",
    "    'cooldown': config_study['cooldown'],\n",
    "    \n",
    "    # Optimizer config (without lr/weight_decay)\n",
    "    'optimizer': {\n",
    "        'mode': 'min',\n",
    "        'factor': config_study['factor'],      # From Optuna\n",
    "        'patience': config_study['patience'],  # From Optuna\n",
    "        'cooldown': config_study['cooldown'],  # From Optuna\n",
    "        'min_lr': 1e-8,\n",
    "        'threshold': 0.0001,\n",
    "    },\n",
    "\n",
    "    # Scheduler config\n",
    "    'scheduler': {\n",
    "        'mode': 'min',\n",
    "        'factor': config_study['factor'],\n",
    "        'patience': config_study['patience'],\n",
    "        'threshold': 0.0001,\n",
    "        'cooldown': config_study['cooldown'],\n",
    "        'min_lr': 1e-8\n",
    "    },\n",
    "\n",
    "    'warmup_epochs': 0,\n",
    "    'grad_clip': None\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #============================================================\n",
    "# # Training Pipeline\n",
    "# #============================================================\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# # Initialize dataset\n",
    "# print(\"Creating full dataset...\")\n",
    "# full_dataset = EEGDataset(config['data_path'])\n",
    "\n",
    "# print(\"Splitting the dataset...\")\n",
    "# # Split dataset\n",
    "# train_set, val_set, test_set = full_dataset.split_dataset(\n",
    "#     ratios=config['split_ratios']\n",
    "# )\n",
    "\n",
    "# del full_dataset\n",
    "\n",
    "# len_dataset = len(train_set)\n",
    "# sample = train_set[0]\n",
    "# label_shape = sample[0].shape\n",
    "# feature_shape = sample[1].shape\n",
    "\n",
    "# print(f\"unbalanced train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "# # # Balance training set\n",
    "# # print(\"Applying SMOTE to train dataset...\")\n",
    "# # train_set.rebalance_by_tsmote()\n",
    "\n",
    "# len_dataset = len(train_set)\n",
    "# sample = train_set[0]\n",
    "# label_shape = sample[0].shape\n",
    "# feature_shape = sample[1].shape\n",
    "\n",
    "# print(f\"balanced train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "# torch.save(train_set, 'train_set.pt')\n",
    "# torch.save(val_set, 'val_set.pt')\n",
    "# torch.save(test_set, 'test_set.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset shape: (1940, [labels: torch.Size([]), features: [2000, 64]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_set = torch.load('train_set_smol.pt', weights_only=False)\n",
    "val_set = torch.load('val_set.pt', weights_only=False)\n",
    "test_set = torch.load('test_set.pt', weights_only=False)\n",
    "\n",
    "\n",
    "generator = torch.Generator().manual_seed(69)  # Set seed\n",
    "train_loader = DataLoader(\n",
    "    train_set,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    generator=generator,  # Add this line\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    # persistent_workers=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "val_loader = DataLoader(val_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=config['batch_size'], collate_fn=collate_fn)\n",
    "\n",
    "len_dataset = len(train_set)\n",
    "sample = train_set[0]\n",
    "label_shape = sample[0].shape\n",
    "feature_shape = sample[1].shape\n",
    "\n",
    "print(f\"train dataset shape: ({len_dataset}, [labels: {label_shape}, features: {list(feature_shape)}])\")\n",
    "\n",
    "\n",
    "# Set up logging\n",
    "writer = SummaryWriter(log_dir=config['log_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f332047d79d45c0acfe77cc90b9c995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start training\n",
    "trained_model = train_model(config, train_set, train_loader, val_loader, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_606700/2930400533.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(f\"{config['log_dir']}/best_model.pth\", map_location=config['device'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db41369564f74b6983350b217437aa7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "best_model = EEGMobileNet()  # Adjust parameters as needed\n",
    "\n",
    "# Load the state dictionary\n",
    "state_dict = torch.load(f\"{config['log_dir']}/best_model.pth\", map_location=config['device'])\n",
    "best_model.load_state_dict(state_dict)\n",
    "\n",
    "# Move model to the correct device\n",
    "best_model = best_model.to(config['device'])\n",
    "\n",
    "# Set model to evaluation mode\n",
    "best_model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "all_test_markers = []\n",
    "all_test_predictions = []\n",
    "with torch.no_grad():\n",
    "    for markers, features in tqdm(test_loader):\n",
    "        features = features.to(config['device'])\n",
    "        markers = markers.to(config['device'])\n",
    "\n",
    "        outputs = best_model(features)\n",
    "\n",
    "        # Collect markers and predictions for metrics calculation\n",
    "        all_test_markers.extend(markers.cpu().numpy().flatten())\n",
    "        all_test_predictions.extend(torch.sigmoid(outputs).cpu().numpy().flatten())\n",
    "\n",
    "# Calculate test metrics\n",
    "test_accuracy = accuracy_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_precision = precision_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_recall = recall_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_f1 = f1_score(all_test_markers, [1 if p > 0.5 else 0 for p in all_test_predictions])\n",
    "test_roc_auc = roc_auc_score(all_test_markers, all_test_predictions)\n",
    "\n",
    "# Log test metrics to TensorBoard\n",
    "writer.add_scalar('Metrics/test_accuracy', test_accuracy, 1)\n",
    "writer.add_scalar('Metrics/test_precision', test_precision, 1)\n",
    "writer.add_scalar('Metrics/test_recall', test_recall, 1)\n",
    "writer.add_scalar('Metrics/test_f1', test_f1, 1)\n",
    "writer.add_scalar('Metrics/test_roc_auc', test_roc_auc, 1)\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test_accuracy=0.5827338129496403\n",
      "test_precision=0.5668202764976958\n",
      "test_recall=0.6059113300492611\n",
      "test_f1=0.5857142857142857\n",
      "test_roc_auc=np.float64(0.5866672805119469)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{test_accuracy=}\n",
    "{test_precision=}\n",
    "{test_recall=}\n",
    "{test_f1=}\n",
    "{test_roc_auc=}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612ac7868c6b4873b09f956dc8a0a91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/90 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.16999999999999998)\n",
      "best_f1=0.6584070796460177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "best_threshold = 0.0\n",
    "best_f1 = 0.0\n",
    "thresholds = np.arange(0.1, 1.0, 0.01)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_recall = f1_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_recall > best_f1:\n",
    "        best_f1 = current_recall\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"{best_f1=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe5fd9b6b3c4671a0088be436b3efae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_threshold=np.float64(0.395)\n",
      "best_accuracy=0.5971223021582733\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "best_threshold = 0.1\n",
    "best_accuracy = 0.0\n",
    "thresholds = np.arange(0.005, 1.0, 0.005)\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    binary_predictions = (all_test_predictions > threshold).astype(int)\n",
    "    current_recall = accuracy_score(all_test_markers, binary_predictions)\n",
    "\n",
    "    if current_recall > best_accuracy:\n",
    "        best_accuracy = current_recall\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"{best_threshold=}\")\n",
    "print(f\"{best_accuracy=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
